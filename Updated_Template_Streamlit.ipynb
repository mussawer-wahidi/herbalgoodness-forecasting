{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4546e43",
   "metadata": {},
   "source": [
    "##### NEW UPDATED CODE AHEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe899d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENHANCED INVENTORY FORECASTING MODEL - COMPREHENSIVE VERSION\n",
      "============================================================\n",
      "Loading data files...\n",
      "   Historical sales: 5048 records\n",
      "   Sample historical SKUs: ['798304169072' '798304441550' '798304395136' '798304169089'\n",
      " '810128952972']\n",
      "Current working directory: c:\\Users\\samiw\\PycharmProjects\\Python_NewProject_First\n",
      "Looking for credentials file...\n",
      "‚úÖ Found credentials file: credentials.json\n",
      "Connecting to Google Sheets...\n",
      "Google Sheets connection established\n",
      "\n",
      "üì¶ Loading inventory data from Google Sheets...\n",
      "üì¶ Extracting inventory data from Google Sheets...\n",
      "‚úÖ Extracted inventory for 153 SKUs\n",
      "   Total inventory records (including variants): 147\n",
      "\n",
      "üîç SAMPLE INVENTORY DATA:\n",
      "   SKU: 'SKU Code' -> Inventory: 0\n",
      "   SKU: 'SKUCode' -> Inventory: 0\n",
      "   SKU: '798304173284' -> Inventory: 1449.0\n",
      "   SKU: '798304169089' -> Inventory: 2561.0\n",
      "   SKU: '810128953108' -> Inventory: 385.0\n",
      "   Current inventory from Google Sheets: 147 SKUs\n",
      "Extracting product data from Google Sheets...\n",
      "‚úÖ Found 'Product Name' in column 1: Product Name\n",
      "‚úÖ Found 'Launch Date' in column 2: Launch Date\n",
      "‚úÖ Found 'UPC/SKU' in column 4: UPC\n",
      "‚úÖ Found 'UPC/SKU' in column 5: Case UPC\n",
      "‚úÖ Found 'UPC/SKU' in column 6: Walmart Unit SKU/ID\n",
      "‚úÖ Found 'Price' in column 16: Status on Pricelist\n",
      "‚úÖ Found 'Price' in column 17: Price\n",
      "‚úÖ Found 'UPC/SKU' in column 20: Product SKU\n",
      "‚úÖ Found 'Lead Time' in column 31: Lead Time\n",
      "‚úÖ Found 'Lead Time' in column 32: Order Lead Time\n",
      "‚úÖ Extracted data for 135 product variations\n",
      "‚úÖ Extracted lead times for 135 product variations\n",
      "‚úÖ Extracted launch dates for 135 product variations\n",
      "\n",
      "üîç SAMPLE EXTRACTED DATA:\n",
      "   SKU: '810128953146' -> Product: 'Ashwagandha Root_Liquid Extract_1oz' | Launch: 2025-05-01 | Lead Time: 2\n",
      "   SKU: '810128953238' -> Product: 'Ashwagandha Root_Liquid Extract_12oz' | Launch: 2025-05-01 | Lead Time: 2\n",
      "   SKU: '810128953115' -> Product: 'Dandelion Root_Liquid Extract_1oz' | Launch: 2025-05-01 | Lead Time: 2\n",
      "   SKU: '810128953221' -> Product: 'Dandelion Root_Liquid Extract_12oz' | Launch: 2025-05-01 | Lead Time: 2\n",
      "   SKU: '810128953023' -> Product: 'Lion's Mane Mushroom_Liquid Extract_12oz' | Launch: 2025-05-01 | Lead Time: 2\n",
      "   Product info from Google Sheets: 135 SKUs\n",
      "   Lead times from Google Sheets: 135 SKUs\n",
      "   Launch dates from Google Sheets: 135 SKUs\n",
      "\n",
      "Loading Amazon FBA weekly sales data...\n",
      "üì¶ Extracting Amazon FBA weekly sales data...\n",
      "üßæ Headers: ['S/N', 'Product Name & Link to Shopify URL', 'Unit UPC', 'ASIN', 'WK 1', 'WK 2', 'WK 3', 'WK 4', 'WK 5', 'WK 6', 'WK 7', 'WK 8', 'WK 9', 'WK 10', 'WK 11', 'WK 12', 'WK 13', 'WK 14', 'WK 15', 'WK 16', 'WK 17', 'WK 18', 'WK 19', 'WK 20', 'WK 21', 'WK 22', 'WK 23', 'WK 24', 'WK 25', 'WK 26', 'WK 27', 'WK 28', 'WK 29', 'WK 30', 'WK 31', 'WK 32', 'WK 33', 'WK 34', 'WK 35', 'WK 36', 'WK 37', 'WK 38', 'WK 39', 'WK 40', 'WK 41', 'WK 42', 'WK 43', 'WK 44', 'WK 45', 'WK 46', 'WK 47', 'WK 48', 'WK 49', 'WK 50', 'WK 51', 'WK 52']\n",
      "‚úÖ Found UPC column at index 2: Unit UPC\n",
      "‚õî Skipping non-date column: WK 1\n",
      "‚õî Skipping non-date column: WK 2\n",
      "‚õî Skipping non-date column: WK 3\n",
      "‚õî Skipping non-date column: WK 4\n",
      "‚õî Skipping non-date column: WK 5\n",
      "‚õî Skipping non-date column: WK 6\n",
      "‚õî Skipping non-date column: WK 7\n",
      "‚õî Skipping non-date column: WK 8\n",
      "‚õî Skipping non-date column: WK 9\n",
      "‚õî Skipping non-date column: WK 10\n",
      "‚õî Skipping non-date column: WK 11\n",
      "‚õî Skipping non-date column: WK 12\n",
      "‚õî Skipping non-date column: WK 13\n",
      "‚õî Skipping non-date column: WK 14\n",
      "‚õî Skipping non-date column: WK 15\n",
      "‚õî Skipping non-date column: WK 16\n",
      "‚õî Skipping non-date column: WK 17\n",
      "‚õî Skipping non-date column: WK 18\n",
      "‚õî Skipping non-date column: WK 19\n",
      "‚õî Skipping non-date column: WK 20\n",
      "‚õî Skipping non-date column: WK 21\n",
      "‚õî Skipping non-date column: WK 22\n",
      "‚õî Skipping non-date column: WK 23\n",
      "‚õî Skipping non-date column: WK 24\n",
      "‚õî Skipping non-date column: WK 25\n",
      "‚õî Skipping non-date column: WK 26\n",
      "‚õî Skipping non-date column: WK 27\n",
      "‚õî Skipping non-date column: WK 28\n",
      "‚õî Skipping non-date column: WK 29\n",
      "‚õî Skipping non-date column: WK 30\n",
      "‚õî Skipping non-date column: WK 31\n",
      "‚õî Skipping non-date column: WK 32\n",
      "‚õî Skipping non-date column: WK 33\n",
      "‚õî Skipping non-date column: WK 34\n",
      "‚õî Skipping non-date column: WK 35\n",
      "‚õî Skipping non-date column: WK 36\n",
      "‚õî Skipping non-date column: WK 37\n",
      "‚õî Skipping non-date column: WK 38\n",
      "‚õî Skipping non-date column: WK 39\n",
      "‚õî Skipping non-date column: WK 40\n",
      "‚õî Skipping non-date column: WK 41\n",
      "‚õî Skipping non-date column: WK 42\n",
      "‚õî Skipping non-date column: WK 43\n",
      "‚õî Skipping non-date column: WK 44\n",
      "‚õî Skipping non-date column: WK 45\n",
      "‚õî Skipping non-date column: WK 46\n",
      "‚õî Skipping non-date column: WK 47\n",
      "‚õî Skipping non-date column: WK 48\n",
      "‚õî Skipping non-date column: WK 49\n",
      "‚õî Skipping non-date column: WK 50\n",
      "‚õî Skipping non-date column: WK 51\n",
      "‚õî Skipping non-date column: WK 52\n",
      "‚ùå Could not identify necessary columns.\n",
      "‚ö†Ô∏è  No Amazon FBA weekly sales data found - using historical data only\n",
      "\n",
      "üîç ENHANCED SKU MATCHING DEBUG:\n",
      "   Historical data has 126 unique SKUs\n",
      "   Google Sheets has 135 unique SKUs\n",
      "   Direct matches: 117\n",
      "   Sample direct matches: ['850035852385', '850035852538', '850035852279', '798304441543', '810128953108']\n",
      "   Testing smart_sku_lookup function:\n",
      "     810128951111 -> Direct: FlowSecure Plus_Liquid Extract_1oz\n",
      "     810128951111 -> In google_skus: True\n",
      "     810128951128 -> Direct: Immune Boost Plus_Liquid Extract_1oz\n",
      "     810128951128 -> In google_skus: True\n",
      "     810128951203 -> Direct: Stone Breaker Plus_Liquid Extract_1oz\n",
      "     810128951203 -> In google_skus: True\n",
      "Initializing Enhanced Forecasting Model...\n",
      "\n",
      "üîç SKU MATCHING DEBUG:\n",
      "Historical data SKUs: 126\n",
      "Lead times SKUs: 135\n",
      "Sample historical SKUs: ['850035852385', '850035852538', '850035852279', '798304441543', '810128953108']\n",
      "Sample lead time SKUs: ['850035852385', '850035852538', '850035852279', '798304441543', '810128953108']\n",
      "Directly matching SKUs: 117\n",
      "Data processed: 5048 records for 126 SKUs\n",
      "Performing ABC velocity analysis...\n",
      "ABC Analysis complete: 1 SKUs categorized\n",
      "\n",
      "Generating forecasts...\n",
      "Creating enhanced forecast for Amazon...\n",
      "Processing 157 SKUs for Amazon\n",
      "Historical periods: Apr_2025, May_2025, Jun_2025\n",
      "Forecast periods: Aug_2025, Sep_2025, Oct_2025, Nov_2025, Dec_2025, Jan_2026, Feb_2026, Mar_2026\n",
      "   Processing SKU 1/157: 850035852385\n",
      "   DEBUG SKU 850035852385: Product = 'Soursop Graviola Leaf Extract_Capsules_60/700mg'\n",
      "   DEBUG SKU 850035852538: Product = 'Guava Leaf_Liquid Extract_12oz'\n",
      "   DEBUG SKU 850035852279: Product = 'Mullein Leaf Tea_Teas_24 Teabags'\n",
      "   DEBUG SKU 798304441543: Product = 'Guayusa Leaf Tea_Teas_24 Teabags'\n",
      "   Error processing SKU 798304441543: list index out of range\n",
      "   DEBUG SKU 810128953108: Product = 'Papaya Leaf_Liquid Extract_1oz'\n",
      "   Error processing SKU 810128951029: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\samiw\\AppData\\Local\\Temp\\ipykernel_30632\\1238479660.py\", line 1042, in create_enhanced_forecast\n",
      "    'Next_Order_Date': order_dates[0],\n",
      "                       ~~~~~~~~~~~^^^\n",
      "IndexError: list index out of range\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\samiw\\AppData\\Local\\Temp\\ipykernel_30632\\1238479660.py\", line 1042, in create_enhanced_forecast\n",
      "    'Next_Order_Date': order_dates[0],\n",
      "                       ~~~~~~~~~~~^^^\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error processing SKU 810128951036: list index out of range\n",
      "   Processing SKU 21/157: 810128953146\n",
      "   Error processing SKU 810128953146: list index out of range\n",
      "   Error processing SKU 810128951234: list index out of range\n",
      "   Error processing SKU 810128951258: list index out of range\n",
      "   Error processing SKU 810128950169: list index out of range\n",
      "   Error processing SKU 850035852361: list index out of range\n",
      "   Error processing SKU 810128950183: list index out of range\n",
      "   Error processing SKU 810128951463: list index out of range\n",
      "   Error processing SKU 810128951319: list index out of range\n",
      "   Error processing SKU 810128950060: list index out of range\n",
      "   Processing SKU 41/157: 810128951098\n",
      "   Error processing SKU 810128951098: list index out of range\n",
      "   Error processing SKU 810128951852: list index out of range\n",
      "   DEBUG SKU 798304493337: Product = 'Mango Leaf_Liquid Extract_1oz'\n",
      "   Error processing SKU 810128953207: list index out of range\n",
      "   Error processing SKU 810128951081: list index out of range\n",
      "   Processing SKU 61/157: 810128953351\n",
      "   Error processing SKU 850035852743: list index out of range\n",
      "   Error processing SKU 810128953016: list index out of range\n",
      "   Error processing SKU 810128950237: list index out of range\n",
      "   Error processing SKU 798304444735: list index out of range\n",
      "   Error processing SKU 810128952859: list index out of range\n",
      "   Error processing SKU 810128953221: list index out of range\n",
      "   Error processing SKU 810128950893: list index out of range\n",
      "   Error processing SKU 850035852804: list index out of range\n",
      "   Error processing SKU 850035852828: list index out of range\n",
      "   Processing SKU 81/157: 810128951197\n",
      "   Error processing SKU 810128953023: list index out of range\n",
      "   Error processing SKU 810128953085: list index out of range\n",
      "   Error processing SKU 850035852620: list index out of range\n",
      "   Error processing SKU 810128951043: list index out of range\n",
      "   Error processing SKU 810128952811: list index out of range\n",
      "   Error processing SKU 850035852880: list index out of range\n",
      "   Error processing SKU 810128953115: list index out of range\n",
      "   Processing SKU 101/157: 798304395150\n",
      "   DEBUG SKU 798304395150: Product = 'Unknown'\n",
      "   Skipping SKU 798304395150 - no product mapping found\n",
      "   Error processing SKU 810128952743: list index out of range\n",
      "   Error processing SKU 810128950268: list index out of range\n",
      "   Error processing SKU 810128951241: list index out of range\n",
      "   Error processing SKU 850035852927: list index out of range\n",
      "   Error processing SKU 810128952804: list index out of range\n",
      "   Processing SKU 121/157: 810128953238\n",
      "   Error processing SKU 810128953238: list index out of range\n",
      "   Error processing SKU 810128952842: list index out of range\n",
      "   Error processing SKU 810128953122: list index out of range\n",
      "   Error processing SKU 810128953047: list index out of range\n",
      "   Error processing SKU 810128951104: list index out of range\n",
      "   Error processing SKU 810128951180: list index out of range\n",
      "   Error processing SKU 810128953511: list index out of range\n",
      "   Error processing SKU 798304471465: list index out of range\n",
      "   Error processing SKU 810128951272: list index out of range\n",
      "   Processing SKU 141/157: 850035852866\n",
      "   Error processing SKU 810128953030: list index out of range\n",
      "   Error processing SKU 810128951128: list index out of range\n",
      "   Error processing SKU 798304441505: list index out of range\n",
      "   DEBUG SKU 850035852408: Product = 'Mushroom Blend_Liquid Extract_12oz'\n",
      "Generated 86 forecasts for Amazon (only mapped products)\n",
      "‚úÖ Successfully mapped 135 product names\n",
      "Creating enhanced forecast for Shopify...\n",
      "Processing 157 SKUs for Shopify\n",
      "Historical periods: Apr_2025, May_2025, Jun_2025\n",
      "Forecast periods: Aug_2025, Sep_2025, Oct_2025, Nov_2025, Dec_2025, Jan_2026, Feb_2026, Mar_2026\n",
      "   Processing SKU 1/157: 850035852385\n",
      "   DEBUG SKU 850035852385: Product = 'Soursop Graviola Leaf Extract_Capsules_60/700mg'\n",
      "   DEBUG SKU 850035852538: Product = 'Guava Leaf_Liquid Extract_12oz'\n",
      "   DEBUG SKU 850035852279: Product = 'Mullein Leaf Tea_Teas_24 Teabags'\n",
      "   DEBUG SKU 798304441543: Product = 'Guayusa Leaf Tea_Teas_24 Teabags'\n",
      "   Error processing SKU 798304441543: list index out of range\n",
      "   DEBUG SKU 810128953108: Product = 'Papaya Leaf_Liquid Extract_1oz'\n",
      "   Error processing SKU 810128953108: list index out of range\n",
      "   Error processing SKU 810128951029: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\samiw\\AppData\\Local\\Temp\\ipykernel_30632\\1238479660.py\", line 1042, in create_enhanced_forecast\n",
      "    'Next_Order_Date': order_dates[0],\n",
      "                       ~~~~~~~~~~~^^^\n",
      "IndexError: list index out of range\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\samiw\\AppData\\Local\\Temp\\ipykernel_30632\\1238479660.py\", line 1042, in create_enhanced_forecast\n",
      "    'Next_Order_Date': order_dates[0],\n",
      "                       ~~~~~~~~~~~^^^\n",
      "IndexError: list index out of range\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\samiw\\AppData\\Local\\Temp\\ipykernel_30632\\1238479660.py\", line 1042, in create_enhanced_forecast\n",
      "    'Next_Order_Date': order_dates[0],\n",
      "                       ~~~~~~~~~~~^^^\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Error processing SKU 810128950251: list index out of range\n",
      "   Processing SKU 21/157: 810128953146\n",
      "   Error processing SKU 810128953146: list index out of range\n",
      "   Error processing SKU 798304451924: list index out of range\n",
      "   Error processing SKU 850035852361: list index out of range\n",
      "   Error processing SKU 810128951463: list index out of range\n",
      "   Error processing SKU 810128951319: list index out of range\n",
      "   Error processing SKU 810128950060: list index out of range\n",
      "   Processing SKU 41/157: 810128951098\n",
      "   Error processing SKU 810128950213: list index out of range\n",
      "   Error processing SKU 810128952835: list index out of range\n",
      "   Error processing SKU 810128951852: list index out of range\n",
      "   DEBUG SKU 798304493337: Product = 'Mango Leaf_Liquid Extract_1oz'\n",
      "   Error processing SKU 810128953207: list index out of range\n",
      "   Error processing SKU 810128951081: list index out of range\n",
      "   Processing SKU 61/157: 810128953351\n",
      "   Error processing SKU 810128953016: list index out of range\n",
      "   Error processing SKU 810128950237: list index out of range\n",
      "   Error processing SKU 850035852569: list index out of range\n",
      "   Error processing SKU 810128952828: list index out of range\n",
      "   Error processing SKU 798304444735: list index out of range\n",
      "   Error processing SKU 810128952859: list index out of range\n",
      "   Error processing SKU 810128953221: list index out of range\n",
      "   Error processing SKU 810128950893: list index out of range\n",
      "   Error processing SKU 850035852804: list index out of range\n",
      "   Error processing SKU 850035852828: list index out of range\n",
      "   Processing SKU 81/157: 810128951197\n",
      "   Error processing SKU 810128953023: list index out of range\n",
      "   Error processing SKU 810128953085: list index out of range\n",
      "   Error processing SKU 850035852620: list index out of range\n",
      "   Error processing SKU 810128952774: list index out of range\n",
      "   Error processing SKU 810128952750: list index out of range\n",
      "   Error processing SKU 810128953115: list index out of range\n",
      "   Processing SKU 101/157: 798304395150\n",
      "   DEBUG SKU 798304395150: Product = 'Unknown'\n",
      "   Skipping SKU 798304395150 - no product mapping found\n",
      "   Error processing SKU 850035852927: list index out of range\n",
      "   Error processing SKU 810128952910: list index out of range\n",
      "   Error processing SKU 810128952804: list index out of range\n",
      "   Processing SKU 121/157: 810128953238\n",
      "   Error processing SKU 810128953238: list index out of range\n",
      "   Error processing SKU 810128952842: list index out of range\n",
      "   Error processing SKU 810128953122: list index out of range\n",
      "   Error processing SKU 810128953511: list index out of range\n",
      "   Processing SKU 141/157: 850035852866\n",
      "   Error processing SKU 810128953030: list index out of range\n",
      "   Error processing SKU 798304441505: list index out of range\n",
      "   DEBUG SKU 850035852408: Product = 'Mushroom Blend_Liquid Extract_12oz'\n",
      "Generated 95 forecasts for Shopify (only mapped products)\n",
      "‚úÖ Successfully mapped 135 product names\n",
      "Creating combined channel analysis...\n",
      "Combining channel forecasts...\n",
      "Found historical columns: ['Apr_2025', 'May_2025', 'Jun_2025']\n",
      "Found forecast columns: ['Forecast_Aug_2025', 'Forecast_Sep_2025', 'Forecast_Oct_2025', 'Forecast_Nov_2025', 'Forecast_Dec_2025', 'Forecast_Jan_2026', 'Forecast_Feb_2026', 'Forecast_Mar_2026']\n",
      "Combined forecasts: 105 unique SKUs\n",
      "Generating actionable insights...\n",
      "Generating actionable insights...\n",
      "Creating finance cash flow forecast...\n",
      "Created finance forecast: 39 orders planned\n",
      "Saving results to enhanced_forecast_COMPREHENSIVE_GoogleSheets_20250710_1725.xlsx...\n",
      "\n",
      "üéâ SUCCESS! Comprehensive enhanced forecasting complete!\n",
      "Results saved to: enhanced_forecast_COMPREHENSIVE_GoogleSheets_20250710_1725.xlsx\n",
      "Total mapped SKUs processed: 105\n",
      "Data source: Google Sheets (with Inventory from https://docs.google.com/spreadsheets/d/1_j7eJi52Kq8RHvK6e0RPBRK8wJ0DXUOMj7Z7yZHlZzM/edit?gid=404505721#gid=404505721)\n",
      "\n",
      "============================================================\n",
      "üìä ACTIONABLE INSIGHTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "üö® IMMEDIATE ACTIONS REQUIRED (2 items):\n",
      "--------------------------------------------------\n",
      "‚Ä¢ Mullein Leaf Tea_Teas_24 Teabags (SKU: 850035852279)\n",
      "  ACTION: EXPEDITE ORDER IMMEDIATELY\n",
      "  REASON: OUT OF STOCK\n",
      "  QUANTITY: 850 units\n",
      "  IMPACT: Lost sales: ~$42500/month\n",
      "\n",
      "‚Ä¢ Soursop Graviola Leaf_Liquid Extract_1oz (SKU: 798304441550)\n",
      "  ACTION: Place PO Today\n",
      "  REASON: Critically low: 0.1 months left\n",
      "  QUANTITY: 743 units\n",
      "  IMPACT: Risk of stockout in 2 months\n",
      "\n",
      "\n",
      "üí∞ CASH FLOW REQUIREMENTS:\n",
      "--------------------------------------------------\n",
      "Next 30 days: $358,830\n",
      "Next 60 days: $0\n",
      "Next 90 days: $0\n",
      "Total PO Value Needed: $73,560\n",
      "\n",
      "üì¶ INVENTORY HEALTH STATUS:\n",
      "--------------------------------------------------\n",
      "At-Risk SKUs (<2 months inventory): 4\n",
      "Overstock SKUs (>6 months inventory): 92\n",
      "Total Inventory Value: $1,834,170\n",
      "\n",
      "üìã ACTION PRIORITY SUMMARY:\n",
      "--------------------------------------------------\n",
      "IMMEDIATE actions required: 0 SKUs\n",
      "HIGH priority actions: 0 SKUs\n",
      "\n",
      "üéØ GROWTH OPPORTUNITIES (2 items):\n",
      "--------------------------------------------------\n",
      "‚Ä¢ Papaya Leaf_Liquid Extract_1oz - +23% growth\n",
      "  ACTION: Increase safety stock\n",
      "\n",
      "‚Ä¢ Papaya Seed_Liquid Extract_1oz - +45% growth\n",
      "  ACTION: Increase safety stock\n",
      "\n",
      "\n",
      "============================================================\n",
      "‚úÖ NEXT STEPS:\n",
      "1. Review 'üö® IMMEDIATE ACTIONS' sheet and place urgent orders TODAY\n",
      "2. Check 'üìä Executive Summary' for overall inventory health\n",
      "3. Use 'üìã Action Priority Matrix' to plan this week's activities\n",
      "4. Review '‚ö†Ô∏è Risk Analysis' to prevent stockouts\n",
      "5. Share 'Finance Cash Flow' sheet with finance team for budget planning\n",
      "============================================================\n",
      "\n",
      "üìä PRODUCT MAPPING SUMMARY:\n",
      "   SKUs with valid product mappings: 105\n",
      "   Mapping success rate: 100% (only mapped products included)\n",
      "   Inventory data source: Google Sheets\n",
      "\n",
      "‚úÖ Successfully mapped products (sample):\n",
      "   850035852385 -> Soursop Graviola Leaf Extract_Capsules_60/700mg\n",
      "   850035852538 -> Guava Leaf_Liquid Extract_12oz\n",
      "   850035852279 -> Mullein Leaf Tea_Teas_24 Teabags\n",
      "   810128953108 -> Papaya Leaf_Liquid Extract_1oz\n",
      "   810128951289 -> Moringa Leaf_Liquid Extract_1oz\n",
      "\n",
      "‚úÖ Ready for inventory planning decisions!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    import gspread\n",
    "    from google.oauth2.service_account import Credentials\n",
    "    GOOGLE_SHEETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GOOGLE_SHEETS_AVAILABLE = False\n",
    "\n",
    "class GoogleSheetsConnector:\n",
    "    def __init__(self, credentials_file='credentials.json'):\n",
    "        if not GOOGLE_SHEETS_AVAILABLE:\n",
    "            raise ImportError(\"Google Sheets packages not available\")\n",
    "\n",
    "        try:\n",
    "            print(\"Connecting to Google Sheets...\")\n",
    "            scopes = [\n",
    "                'https://www.googleapis.com/auth/spreadsheets.readonly',\n",
    "                'https://www.googleapis.com/auth/drive.readonly'\n",
    "            ]\n",
    "            credentials = Credentials.from_service_account_file(credentials_file, scopes=scopes)\n",
    "            self.gc = gspread.authorize(credentials)\n",
    "            print(\"Google Sheets connection established\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to Google Sheets: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_inventory_data(self, spreadsheet_url):\n",
    "        \"\"\"\n",
    "        Extract inventory data from Google Sheets\n",
    "        Column B: SKU\n",
    "        Column AC: Inventory total\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"üì¶ Extracting inventory data from Google Sheets...\")\n",
    "            spreadsheet = self.gc.open_by_url(spreadsheet_url)\n",
    "            \n",
    "            # Get the first worksheet (or specify the worksheet name if needed)\n",
    "            worksheet = spreadsheet.get_worksheet(0)  # First sheet\n",
    "            \n",
    "            # Get all values\n",
    "            all_values = worksheet.get_all_values()\n",
    "            \n",
    "            if not all_values:\n",
    "                print(\"‚ùå No data found in inventory sheet\")\n",
    "                return {}\n",
    "            \n",
    "            # Find column indices (B = index 1, AC = index 28)\n",
    "            sku_col = 1  # Column B\n",
    "            inventory_col = 28  # Column AC\n",
    "            \n",
    "            inventory_data = {}\n",
    "            skus_processed = 0\n",
    "            \n",
    "            # Process data rows (assuming row 1 is header)\n",
    "            for row_idx, row in enumerate(all_values[1:], start=2):\n",
    "                try:\n",
    "                    # Ensure row has enough columns\n",
    "                    if len(row) <= max(sku_col, inventory_col):\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract SKU\n",
    "                    raw_sku = str(row[sku_col]).strip()\n",
    "                    if not raw_sku or raw_sku.lower() in ['', 'none', 'null', 'n/a']:\n",
    "                        continue\n",
    "                    \n",
    "                    # Clean SKU - multiple formats\n",
    "                    cleaned_skus = []\n",
    "                    \n",
    "                    # Original format\n",
    "                    cleaned_skus.append(raw_sku)\n",
    "                    \n",
    "                    # Remove leading zeros\n",
    "                    cleaned_skus.append(raw_sku.lstrip('0'))\n",
    "                    \n",
    "                    # Add leading zeros if short UPC\n",
    "                    if raw_sku.isdigit() and len(raw_sku) < 12:\n",
    "                        cleaned_skus.append(raw_sku.zfill(12))\n",
    "                    \n",
    "                    # Remove non-alphanumeric\n",
    "                    alphanumeric_only = ''.join(c for c in raw_sku if c.isalnum())\n",
    "                    if alphanumeric_only:\n",
    "                        cleaned_skus.append(alphanumeric_only)\n",
    "                    \n",
    "                    # Extract inventory quantity\n",
    "                    inventory_value = row[inventory_col] if inventory_col < len(row) else '0'\n",
    "                    \n",
    "                    try:\n",
    "                        inventory_qty = float(str(inventory_value).replace(',', '').strip())\n",
    "                        if inventory_qty < 0:\n",
    "                            inventory_qty = 0\n",
    "                    except:\n",
    "                        inventory_qty = 0\n",
    "                    \n",
    "                    # Store all SKU variations with the same inventory value\n",
    "                    for sku_variant in cleaned_skus:\n",
    "                        if sku_variant:\n",
    "                            inventory_data[sku_variant] = inventory_qty\n",
    "                            \n",
    "                    skus_processed += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   Warning: Error processing row {row_idx}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"‚úÖ Extracted inventory for {skus_processed} SKUs\")\n",
    "            print(f\"   Total inventory records (including variants): {len(inventory_data)}\")\n",
    "            \n",
    "            # Show sample data\n",
    "            if inventory_data:\n",
    "                print(f\"\\nüîç SAMPLE INVENTORY DATA:\")\n",
    "                sample_items = list(inventory_data.items())[:5]\n",
    "                for sku, qty in sample_items:\n",
    "                    print(f\"   SKU: '{sku}' -> Inventory: {qty}\")\n",
    "            \n",
    "            return inventory_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error extracting inventory data: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return {}\n",
    "\n",
    "    def get_product_data(self, spreadsheet_url):\n",
    "        try:\n",
    "            print(\"Extracting product data from Google Sheets...\")\n",
    "            spreadsheet = self.gc.open_by_url(spreadsheet_url)\n",
    "            worksheet = spreadsheet.worksheet(\"1. Finished_Products\")\n",
    "\n",
    "            # Get all values to handle duplicate headers manually\n",
    "            all_values = worksheet.get_all_values()\n",
    "\n",
    "            if not all_values:\n",
    "                print(\"No data found in the worksheet\")\n",
    "                return {}, {}, {}\n",
    "\n",
    "            # Get headers and clean them\n",
    "            headers = all_values[0]\n",
    "\n",
    "            # Find the columns we need by index - MORE FLEXIBLE MATCHING\n",
    "            product_name_col = None\n",
    "            launch_date_col = None\n",
    "            upc_col = None\n",
    "            price_col = None\n",
    "            lead_time_col = None\n",
    "\n",
    "            # Look for our target columns (case insensitive and partial matching)\n",
    "            for i, header in enumerate(headers):\n",
    "                header_clean = str(header).strip().lower()\n",
    "\n",
    "                if any(keyword in header_clean for keyword in ['product name', 'product_name', 'name']):\n",
    "                    product_name_col = i\n",
    "                    print(f\"‚úÖ Found 'Product Name' in column {i}: {header}\")\n",
    "                elif any(keyword in header_clean for keyword in ['launch date', 'launch_date', 'date']):\n",
    "                    launch_date_col = i\n",
    "                    print(f\"‚úÖ Found 'Launch Date' in column {i}: {header}\")\n",
    "                elif any(keyword in header_clean for keyword in ['upc', 'sku', 'barcode', 'unit upc']):\n",
    "                    upc_col = i\n",
    "                    print(f\"‚úÖ Found 'UPC/SKU' in column {i}: {header}\")\n",
    "                elif any(keyword in header_clean for keyword in ['price', 'cost', 'msrp']):\n",
    "                    price_col = i\n",
    "                    print(f\"‚úÖ Found 'Price' in column {i}: {header}\")\n",
    "                elif any(keyword in header_clean for keyword in ['lead time', 'lead_time', 'leadtime']):\n",
    "                    lead_time_col = i\n",
    "                    print(f\"‚úÖ Found 'Lead Time' in column {i}: {header}\")\n",
    "\n",
    "            if upc_col is None:\n",
    "                print(\"‚ùå Could not find UPC/SKU column\")\n",
    "                return {}, {}, {}\n",
    "\n",
    "            product_info = {}\n",
    "            lead_times = {}\n",
    "            launch_dates = {}  # Store launch dates for each SKU\n",
    "            sku_variations = {}  # Track different formats of the same SKU\n",
    "\n",
    "            # Process data rows (skip header row)\n",
    "            for row_idx, row in enumerate(all_values[1:], start=2):\n",
    "                try:\n",
    "                    # Ensure row has enough columns\n",
    "                    if len(row) <= max(filter(None, [product_name_col, launch_date_col, upc_col, price_col, lead_time_col])):\n",
    "                        continue\n",
    "\n",
    "                    # Extract UPC/SKU with multiple cleaning approaches\n",
    "                    raw_upc = str(row[upc_col]).strip() if upc_col < len(row) else ''\n",
    "                    if not raw_upc or raw_upc.lower() in ['', 'none', 'null', 'n/a']:\n",
    "                        continue\n",
    "\n",
    "                    # Clean UPC/SKU - try multiple formats\n",
    "                    cleaned_upcs = []\n",
    "\n",
    "                    # Original format\n",
    "                    cleaned_upcs.append(raw_upc)\n",
    "\n",
    "                    # Remove leading zeros (common issue)\n",
    "                    cleaned_upcs.append(raw_upc.lstrip('0'))\n",
    "\n",
    "                    # Add leading zeros if it looks like a short UPC\n",
    "                    if raw_upc.isdigit() and len(raw_upc) < 12:\n",
    "                        cleaned_upcs.append(raw_upc.zfill(12))\n",
    "\n",
    "                    # Remove all non-alphanumeric characters\n",
    "                    alphanumeric_only = ''.join(c for c in raw_upc if c.isalnum())\n",
    "                    if alphanumeric_only:\n",
    "                        cleaned_upcs.append(alphanumeric_only)\n",
    "\n",
    "                    # Remove spaces and dashes\n",
    "                    no_spaces_dashes = raw_upc.replace(' ', '').replace('-', '')\n",
    "                    if no_spaces_dashes:\n",
    "                        cleaned_upcs.append(no_spaces_dashes)\n",
    "\n",
    "                    # Extract other data\n",
    "                    product_name = str(row[product_name_col]).strip() if product_name_col is not None and product_name_col < len(row) else 'Unknown'\n",
    "                    launch_date_raw = str(row[launch_date_col]).strip() if launch_date_col is not None and launch_date_col < len(row) else ''\n",
    "                    price = row[price_col] if price_col is not None and price_col < len(row) else 0\n",
    "                    lead_time = row[lead_time_col] if lead_time_col is not None and lead_time_col < len(row) else 2\n",
    "\n",
    "                    # Clean and parse launch date\n",
    "                    launch_date_parsed = None\n",
    "                    if launch_date_raw and launch_date_raw.lower() not in ['', 'none', 'null', 'n/a']:\n",
    "                        try:\n",
    "                            # Try multiple date formats\n",
    "                            for date_format in ['%m/%d/%Y', '%Y-%m-%d', '%m-%d-%Y', '%d/%m/%Y', '%Y/%m/%d']:\n",
    "                                try:\n",
    "                                    launch_date_parsed = pd.to_datetime(launch_date_raw, format=date_format)\n",
    "                                    break\n",
    "                                except:\n",
    "                                    continue\n",
    "\n",
    "                            # If still not parsed, try pandas auto-detection\n",
    "                            if launch_date_parsed is None:\n",
    "                                launch_date_parsed = pd.to_datetime(launch_date_raw, errors='coerce')\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"   Warning: Could not parse launch date '{launch_date_raw}' for row {row_idx}\")\n",
    "                            launch_date_parsed = None\n",
    "\n",
    "                    # Clean and validate data\n",
    "                    try:\n",
    "                        price = float(str(price).replace('$', '').replace(',', '')) if price else 0\n",
    "                    except:\n",
    "                        price = 0\n",
    "\n",
    "                    try:\n",
    "                        lead_time = int(float(str(lead_time))) if lead_time else 2\n",
    "                    except:\n",
    "                        lead_time = 2\n",
    "\n",
    "                    # Store all UPC variations for this product\n",
    "                    for upc_variant in cleaned_upcs:\n",
    "                        if upc_variant and upc_variant not in product_info:\n",
    "                            product_info[upc_variant] = product_name\n",
    "                            lead_times[upc_variant] = lead_time\n",
    "                            launch_dates[upc_variant] = launch_date_parsed  # Store parsed date\n",
    "                            sku_variations[upc_variant] = {\n",
    "                                'original': raw_upc,\n",
    "                                'product_name': product_name,\n",
    "                                'launch_date': launch_date_parsed,\n",
    "                                'row': row_idx\n",
    "                            }\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing row {row_idx}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            print(f\"‚úÖ Extracted data for {len(product_info)} product variations\")\n",
    "            print(f\"‚úÖ Extracted lead times for {len(lead_times)} product variations\")\n",
    "            print(f\"‚úÖ Extracted launch dates for {len([d for d in launch_dates.values() if d is not None])} product variations\")\n",
    "\n",
    "            # Debug: Show some examples of what we extracted\n",
    "            print(f\"\\nüîç SAMPLE EXTRACTED DATA:\")\n",
    "            sample_items = list(product_info.items())[:5]\n",
    "            for sku, name in sample_items:\n",
    "                launch_info = launch_dates.get(sku)\n",
    "                launch_str = launch_info.strftime('%Y-%m-%d') if launch_info else 'No Date'\n",
    "                print(f\"   SKU: '{sku}' -> Product: '{name}' | Launch: {launch_str} | Lead Time: {lead_times.get(sku, 'N/A')}\")\n",
    "\n",
    "            return product_info, lead_times, launch_dates\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error extracting product data: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return {}, {}, {}\n",
    "\n",
    "    def get_amazon_fba_weekly_sales(self, spreadsheet_url):\n",
    "        try:\n",
    "            print(\"üì¶ Extracting Amazon FBA weekly sales data...\")\n",
    "            spreadsheet = self.gc.open_by_url(spreadsheet_url)\n",
    "            worksheet = spreadsheet.worksheet(\"Summary (All)\")\n",
    "\n",
    "            all_values = worksheet.get_all_values()\n",
    "            if not all_values:\n",
    "                print(\"‚ùå No data found.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            headers = all_values[0]\n",
    "            print(f\"üßæ Headers: {headers}\")\n",
    "\n",
    "            sku_col = None\n",
    "            week_columns = []\n",
    "\n",
    "            # Identify columns\n",
    "            for i, header in enumerate(headers):\n",
    "                header_clean = str(header).strip().lower()\n",
    "\n",
    "                if 'upc' in header_clean:\n",
    "                    sku_col = i\n",
    "                    print(f\"‚úÖ Found UPC column at index {i}: {header}\")\n",
    "                    continue\n",
    "\n",
    "                # Try to parse as date\n",
    "                try:\n",
    "                    week_date = pd.to_datetime(header, dayfirst=False)  # mm/dd/yyyy format\n",
    "                    week_columns.append((i, week_date))\n",
    "                    print(f\"üìÖ Week column at index {i}: {week_date.strftime('%d/%m/%Y')}\")\n",
    "                except:\n",
    "                    # Print once for debugging\n",
    "                    if i >= 4:  # Avoid clutter for known non-date columns\n",
    "                        print(f\"‚õî Skipping non-date column: {header}\")\n",
    "                    continue\n",
    "\n",
    "            if sku_col is None or not week_columns:\n",
    "                print(\"‚ùå Could not identify necessary columns.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            # Parse each row\n",
    "            weekly_sales_data = []\n",
    "            processed_skus = set()\n",
    "\n",
    "            for row_idx, row in enumerate(all_values[1:], start=2):\n",
    "                try:\n",
    "                    if len(row) <= sku_col:\n",
    "                        continue\n",
    "\n",
    "                    raw_sku = str(row[sku_col]).strip()\n",
    "                    if not raw_sku or raw_sku.lower() in ['none', 'null', 'n/a', '']:\n",
    "                        continue\n",
    "\n",
    "                    # Clean SKU\n",
    "                    cleaned_sku = raw_sku.zfill(12) if raw_sku.isdigit() and len(raw_sku) < 12 else raw_sku\n",
    "                    processed_skus.add(cleaned_sku)\n",
    "\n",
    "                    for col_idx, week_date in week_columns:\n",
    "                        if col_idx >= len(row):\n",
    "                            continue\n",
    "                        try:\n",
    "                            sales = float(row[col_idx]) if row[col_idx].strip() not in ['', '-', 'n/a', 'N/A'] else 0\n",
    "                        except:\n",
    "                            sales = 0\n",
    "\n",
    "                        if sales > 0:\n",
    "                            weekly_sales_data.append({\n",
    "                                'SKU': cleaned_sku,\n",
    "                                'Original_SKU': raw_sku,\n",
    "                                'Week_Start': week_date,\n",
    "                                'Sales': sales,\n",
    "                                'Channel': 'Amazon'\n",
    "                            })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error at row {row_idx}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # Convert to DataFrame\n",
    "            weekly_df = pd.DataFrame(weekly_sales_data)\n",
    "\n",
    "            if weekly_df.empty:\n",
    "                print(\"‚ö†Ô∏è No valid weekly sales found.\")\n",
    "            else:\n",
    "                print(f\"‚úÖ {len(weekly_df)} records extracted | {weekly_df['SKU'].nunique()} SKUs\")\n",
    "                print(f\"   Range: {weekly_df['Week_Start'].min().strftime('%d/%m/%Y')} ‚Üí {weekly_df['Week_Start'].max().strftime('%d/%m/%Y')}\")\n",
    "\n",
    "            return weekly_df\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fatal error during extraction: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "    def convert_amazon_weekly_to_monthly(self, weekly_df):\n",
    "        \"\"\"\n",
    "        Convert Amazon FBA weekly sales data to monthly format\n",
    "        using actual week start dates.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if weekly_df.empty:\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            print(f\"Converting Amazon FBA weekly sales to monthly format...\")\n",
    "\n",
    "            # Ensure 'Week_Start' column is datetime\n",
    "            weekly_df['Week_Start'] = pd.to_datetime(weekly_df['Week_Start'], errors='coerce')\n",
    "\n",
    "            # Drop rows with invalid dates\n",
    "            weekly_df = weekly_df.dropna(subset=['Week_Start'])\n",
    "\n",
    "            # Assign the month (e.g., 2025-01-31, 2025-02-28 etc.) to each week using MonthEnd\n",
    "            weekly_df['Month'] = weekly_df['Week_Start'] + pd.offsets.MonthEnd(0)\n",
    "\n",
    "            # Debug print mapping\n",
    "            mapping = weekly_df[['Week_Start', 'Month']].drop_duplicates().sort_values('Week_Start')\n",
    "            print(\"Week to Month mapping:\")\n",
    "            for _, row in mapping.head(10).iterrows():\n",
    "                print(f\"   Week of {row['Week_Start'].strftime('%d/%m/%Y')} ‚Üí Month End: {row['Month'].strftime('%d/%m/%Y')}\")\n",
    "\n",
    "            # Group and aggregate\n",
    "            monthly_sales = weekly_df.groupby(['SKU', 'Month'])['Sales'].sum().reset_index()\n",
    "            monthly_sales['Channel'] = 'Amazon'\n",
    "            monthly_sales = monthly_sales.rename(columns={'Month': 'Date'})\n",
    "\n",
    "            print(f\"‚úÖ Converted to {len(monthly_sales)} monthly records\")\n",
    "            print(f\"   Date range: {monthly_sales['Date'].min().strftime('%d/%m/%Y')} to {monthly_sales['Date'].max().strftime('%d/%m/%Y')}\")\n",
    "            print(f\"   SKUs covered: {monthly_sales['SKU'].nunique()}\")\n",
    "\n",
    "            # Sample output\n",
    "            for _, row in monthly_sales.head(3).iterrows():\n",
    "                print(f\"   SKU {row['SKU']} | {row['Date'].strftime('%b %Y')} | Sales: {row['Sales']}\")\n",
    "\n",
    "            return monthly_sales\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error converting Amazon FBA weekly to monthly: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def extend_historical_data_with_amazon_weekly(self, historical_data, amazon_weekly_monthly_data):\n",
    "        \"\"\"\n",
    "        Extend historical sales data with Amazon FBA weekly data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if amazon_weekly_monthly_data.empty:\n",
    "                print(\"No Amazon FBA weekly data to extend historical data\")\n",
    "                return historical_data\n",
    "\n",
    "            print(\"Extending historical data with Amazon FBA weekly sales...\")\n",
    "\n",
    "            # Get the latest date in historical data\n",
    "            historical_data['Date'] = pd.to_datetime(historical_data['Date'])\n",
    "            latest_historical_date = historical_data['Date'].max()\n",
    "\n",
    "            print(f\"Latest historical date: {latest_historical_date}\")\n",
    "            print(f\"Amazon FBA weekly data starts: {amazon_weekly_monthly_data['Date'].min()}\")\n",
    "            print(f\"Amazon FBA weekly data ends: {amazon_weekly_monthly_data['Date'].max()}\")\n",
    "\n",
    "            # Filter Amazon weekly data to only include dates after historical data\n",
    "            new_amazon_data = amazon_weekly_monthly_data[amazon_weekly_monthly_data['Date'] > latest_historical_date].copy()\n",
    "\n",
    "            if new_amazon_data.empty:\n",
    "                print(\"No new Amazon FBA weekly data after historical cutoff\")\n",
    "                return historical_data\n",
    "\n",
    "            print(f\"Adding {len(new_amazon_data)} new Amazon FBA monthly records\")\n",
    "\n",
    "            # Amazon FBA data is already in the right format - just add it\n",
    "            if not new_amazon_data.empty:\n",
    "                # Combine with historical data\n",
    "                combined_data = pd.concat([historical_data, new_amazon_data], ignore_index=True)\n",
    "                combined_data = combined_data.sort_values(['SKU', 'Channel', 'Date'])\n",
    "\n",
    "                print(f\"‚úÖ Extended historical data with {len(new_amazon_data)} new Amazon records\")\n",
    "                print(f\"   Total records: {len(combined_data)} (was {len(historical_data)})\")\n",
    "                print(f\"   New date range: {combined_data['Date'].min()} to {combined_data['Date'].max()}\")\n",
    "\n",
    "                # Show sample of extended data\n",
    "                amazon_sample = new_amazon_data.head(3)\n",
    "                for _, row in amazon_sample.iterrows():\n",
    "                    print(f\"   Added Amazon: {row['SKU']}, {row['Date'].strftime('%b %Y')}, Sales: {row['Sales']}\")\n",
    "\n",
    "                return combined_data\n",
    "            else:\n",
    "                return historical_data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error extending historical data with Amazon FBA: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return historical_data\n",
    "\n",
    "# [REST OF THE CODE REMAINS EXACTLY THE SAME FROM EnhancedForecastingModel CLASS ONWARDS]\n",
    "# Including all methods in EnhancedForecastingModel and the main() function\n",
    "# Only the inventory loading part in main() needs to be modified\n",
    "\n",
    "class EnhancedForecastingModel:\n",
    "    def __init__(self, historical_data, lead_times, launch_dates, service_level=0.95):\n",
    "        try:\n",
    "            print(\"Initializing Enhanced Forecasting Model...\")\n",
    "\n",
    "            expected_columns = ['SKU', 'Channel', 'Date', 'Sales']\n",
    "            missing_cols = [col for col in expected_columns if col not in historical_data.columns]\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Missing columns: {missing_cols}\")\n",
    "\n",
    "            # Clean SKU data more thoroughly\n",
    "            historical_data['SKU'] = historical_data['SKU'].astype(str).str.strip()\n",
    "            historical_data['Date'] = pd.to_datetime(historical_data['Date'], format='%m/%d/%Y', errors='coerce')\n",
    "            historical_data = historical_data.dropna(subset=['Date'])\n",
    "            historical_data['Channel'] = historical_data['Channel'].str.strip().str.capitalize()\n",
    "            historical_data = historical_data[historical_data['Channel'].isin(['Amazon', 'Shopify'])]\n",
    "            historical_data['Sales'] = pd.to_numeric(historical_data['Sales'], errors='coerce').fillna(0)\n",
    "\n",
    "            self.data = historical_data\n",
    "            self.lead_times = lead_times\n",
    "            self.launch_dates = launch_dates\n",
    "            self.service_level = service_level\n",
    "            self.z_score = norm.ppf(service_level)\n",
    "\n",
    "            # Debug SKU matching\n",
    "            print(f\"\\nüîç SKU MATCHING DEBUG:\")\n",
    "            historical_skus = set(self.data['SKU'].unique())\n",
    "            lead_time_skus = set(lead_times.keys())\n",
    "\n",
    "            print(f\"Historical data SKUs: {len(historical_skus)}\")\n",
    "            print(f\"Lead times SKUs: {len(lead_time_skus)}\")\n",
    "\n",
    "            # Show sample SKUs from each source\n",
    "            print(f\"Sample historical SKUs: {list(historical_skus)[:5]}\")\n",
    "            print(f\"Sample lead time SKUs: {list(lead_time_skus)[:5]}\")\n",
    "\n",
    "            # Check for matches\n",
    "            matching_skus = historical_skus.intersection(lead_time_skus)\n",
    "            print(f\"Directly matching SKUs: {len(matching_skus)}\")\n",
    "\n",
    "            print(f\"Data processed: {len(self.data)} records for {self.data['SKU'].nunique()} SKUs\")\n",
    "\n",
    "            self.velocity_categories = self._perform_abc_analysis()\n",
    "            print(f\"ABC Analysis complete: {len(self.velocity_categories)} SKUs categorized\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing model: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _perform_abc_analysis(self):\n",
    "        try:\n",
    "            print(\"Performing ABC velocity analysis...\")\n",
    "\n",
    "            latest_date = self.data['Date'].max()\n",
    "            cutoff_date = latest_date - pd.DateOffset(months=3)\n",
    "            recent_data = self.data[self.data['Date'] >= cutoff_date]\n",
    "\n",
    "            if recent_data.empty:\n",
    "                recent_data = self.data.copy()\n",
    "\n",
    "            sku_sales = recent_data.groupby('SKU')['Sales'].sum().sort_values(ascending=False)\n",
    "\n",
    "            categories = {}\n",
    "            total_skus = len(sku_sales)\n",
    "\n",
    "            for i, (sku, sales) in enumerate(sku_sales.items()):\n",
    "                rank = i + 1\n",
    "\n",
    "                if rank <= 20 or rank <= total_skus * 0.10:\n",
    "                    category = 'A'\n",
    "                    safety_months = 3.0\n",
    "                    service_level = 0.98\n",
    "                elif rank <= total_skus * 0.30:\n",
    "                    category = 'B'\n",
    "                    safety_months = 2.0\n",
    "                    service_level = 0.95\n",
    "                elif rank <= total_skus * 0.70:\n",
    "                    category = 'C'\n",
    "                    safety_months = 1.5\n",
    "                    service_level = 0.90\n",
    "                else:\n",
    "                    category = 'D'\n",
    "                    safety_months = 1.0\n",
    "                    service_level = 0.85\n",
    "\n",
    "                categories[sku] = {\n",
    "                    'category': category,\n",
    "                    'rank': rank,\n",
    "                    'total_sales': sales,\n",
    "                    'monthly_velocity': sales / 3,\n",
    "                    'safety_stock_months': safety_months,\n",
    "                    'service_level': service_level\n",
    "                }\n",
    "\n",
    "            return categories\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in ABC analysis: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def smart_sku_lookup(self, sku, product_info, data_dict=None):\n",
    "        \"\"\"\n",
    "        Enhanced SKU lookup that tries multiple matching strategies\n",
    "        Can return product info or any other data from data_dict\n",
    "        \"\"\"\n",
    "        sku = str(sku).strip()\n",
    "\n",
    "        # Choose which dictionary to use for lookup\n",
    "        lookup_dict = data_dict if data_dict is not None else product_info\n",
    "\n",
    "        # Direct match first\n",
    "        if sku in lookup_dict:\n",
    "            return lookup_dict[sku]\n",
    "\n",
    "        # Try variations of the SKU\n",
    "        sku_variations = [\n",
    "            sku.lstrip('0'),  # Remove leading zeros\n",
    "            sku.zfill(12),    # Pad with zeros to 12 digits\n",
    "            ''.join(c for c in sku if c.isalnum()),  # Remove special characters\n",
    "            sku.replace(' ', '').replace('-', '')     # Remove spaces and dashes\n",
    "        ]\n",
    "\n",
    "        for variant in sku_variations:\n",
    "            if variant and variant in lookup_dict:\n",
    "                return lookup_dict[variant]\n",
    "\n",
    "        # Try partial matching (both ways)\n",
    "        for lookup_sku, value in lookup_dict.items():\n",
    "            # Check if either SKU contains the other\n",
    "            if len(sku) >= 8 and len(lookup_sku) >= 8:  # Only for reasonable length SKUs\n",
    "                if sku in lookup_sku or lookup_sku in sku:\n",
    "                    return value\n",
    "\n",
    "        # Return appropriate default based on data type\n",
    "        if data_dict is None:  # product_info lookup\n",
    "            return 'Unknown'\n",
    "        else:  # Could be launch_dates or other data\n",
    "            return None\n",
    "\n",
    "    def calculate_years_since_launch(self, sku, current_date=None):\n",
    "        \"\"\"\n",
    "        Calculate the number of years since product launch (with decimal precision)\n",
    "        \"\"\"\n",
    "        if current_date is None:\n",
    "            current_date = pd.Timestamp.now()\n",
    "\n",
    "        launch_date = self.smart_sku_lookup(sku, None, self.launch_dates)\n",
    "\n",
    "        if launch_date is None or pd.isna(launch_date):\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # Calculate the difference in years with decimal precision\n",
    "            years_diff = (current_date - launch_date).days / 365.25  # Account for leap years\n",
    "            return round(years_diff, 1) if years_diff >= 0 else 0.0\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def prepare_data(self, channel, sku):\n",
    "        try:\n",
    "            sku = str(sku).strip()\n",
    "            channel = str(channel).strip().capitalize()\n",
    "\n",
    "            sku_data = self.data[(self.data['SKU'] == sku) & (self.data['Channel'] == channel)].sort_values('Date')\n",
    "\n",
    "            if sku_data.empty:\n",
    "                date_range = pd.date_range(start='2024-01-01', end='2025-04-30', freq='ME')\n",
    "                return pd.Series([0] * len(date_range), index=date_range)\n",
    "\n",
    "            sku_data['Month'] = sku_data['Date'].dt.to_period('M').dt.to_timestamp('M')\n",
    "            monthly_sales = sku_data.groupby('Month')['Sales'].sum().sort_index()\n",
    "\n",
    "            full_range = pd.date_range(start=monthly_sales.index.min(), end=monthly_sales.index.max(), freq='ME')\n",
    "            monthly_sales = monthly_sales.reindex(full_range, fill_value=0)\n",
    "            monthly_sales.index.freq = 'ME'\n",
    "\n",
    "            return monthly_sales\n",
    "\n",
    "        except Exception:\n",
    "            date_range = pd.date_range(start='2024-01-01', end='2025-04-30', freq='ME')\n",
    "            return pd.Series([0] * len(date_range), index=date_range)\n",
    "\n",
    "    def generate_forecast(self, series, horizon=8):\n",
    "        try:\n",
    "            growth_rate = self._calculate_growth_rate(series)\n",
    "\n",
    "            if series.empty or series.sum() == 0:\n",
    "                last_date = series.index[-1] if not series.empty else pd.to_datetime('2025-04-30')\n",
    "                forecast_dates = pd.date_range(start=last_date + pd.offsets.MonthEnd(1), periods=horizon, freq='ME')\n",
    "                forecast = pd.Series([0] * horizon, index=forecast_dates)\n",
    "                return forecast, 'Zero Forecast', 0, [], 0\n",
    "\n",
    "            mean_sales = series.mean()\n",
    "            std_sales = series.std()\n",
    "            cv = std_sales / mean_sales if mean_sales > 0 else float('inf')\n",
    "\n",
    "            if cv > 3 or len(series) < 3:\n",
    "                avg_forecast = max(mean_sales, 0)\n",
    "                forecast_values = [max(0, round(avg_forecast + growth_rate * (i + 1))) for i in range(horizon)]\n",
    "                last_date = series.index[-1]\n",
    "                forecast_dates = pd.date_range(start=last_date + pd.offsets.MonthEnd(1), periods=horizon, freq='ME')\n",
    "                forecast = pd.Series(forecast_values, index=forecast_dates)\n",
    "                return forecast, 'Average + Growth', 0, [], growth_rate\n",
    "\n",
    "            try:\n",
    "                if len(series) >= 12:\n",
    "                    model = ExponentialSmoothing(series, seasonal='add', seasonal_periods=6, trend='add').fit()\n",
    "                    method = 'Holt-Winters Seasonal'\n",
    "                elif len(series) >= 6:\n",
    "                    model = ExponentialSmoothing(series, trend='add').fit()\n",
    "                    method = 'Holt-Winters Trend'\n",
    "                else:\n",
    "                    model = ExponentialSmoothing(series).fit()\n",
    "                    method = 'Simple Exponential Smoothing'\n",
    "\n",
    "                forecast = model.forecast(horizon)\n",
    "                forecast = forecast.clip(lower=0, upper=series.max() * 5)\n",
    "\n",
    "                last_date = series.index[-1]\n",
    "                forecast_dates = pd.date_range(start=last_date + pd.offsets.MonthEnd(1), periods=horizon, freq='ME')\n",
    "                forecast.index = forecast_dates\n",
    "\n",
    "                return forecast.round().astype(int), method, 6, [], growth_rate\n",
    "\n",
    "            except Exception:\n",
    "                avg_forecast = max(mean_sales, 0)\n",
    "                forecast_values = [max(0, round(avg_forecast + growth_rate * (i + 1))) for i in range(horizon)]\n",
    "                last_date = series.index[-1]\n",
    "                forecast_dates = pd.date_range(start=last_date + pd.offsets.MonthEnd(1), periods=horizon, freq='ME')\n",
    "                forecast = pd.Series(forecast_values, index=forecast_dates)\n",
    "                return forecast, 'Fallback Average', 0, [], growth_rate\n",
    "\n",
    "        except Exception:\n",
    "            last_date = pd.to_datetime('2025-04-30')\n",
    "            forecast_dates = pd.date_range(start=last_date + pd.offsets.MonthEnd(1), periods=horizon, freq='ME')\n",
    "            forecast = pd.Series([0] * horizon, index=forecast_dates)\n",
    "            return forecast, 'Error Fallback', 0, [], 0\n",
    "\n",
    "    def _calculate_growth_rate(self, series):\n",
    "        try:\n",
    "            if len(series) < 2:\n",
    "                return 0\n",
    "            x = np.arange(len(series)).reshape(-1, 1)\n",
    "            y = series.values.reshape(-1, 1)\n",
    "            model = LinearRegression()\n",
    "            model.fit(x, y)\n",
    "            growth_rate = round(model.coef_[0][0], 2)\n",
    "            # Handle NaN/Inf values\n",
    "            if pd.isna(growth_rate) or growth_rate == float('inf') or growth_rate == float('-inf'):\n",
    "                return 0\n",
    "            return growth_rate\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def calculate_enhanced_safety_stock(self, series, lead_time, sku):\n",
    "        try:\n",
    "            sku_info = self.velocity_categories.get(sku, {})\n",
    "            category = sku_info.get('category', 'D')\n",
    "            target_service_level = sku_info.get('service_level', 0.85)\n",
    "            safety_months = sku_info.get('safety_stock_months', 1.0)\n",
    "\n",
    "            z_score = norm.ppf(target_service_level)\n",
    "\n",
    "            if len(series) < 2 or series.sum() == 0:\n",
    "                return max(round(safety_months * 10), 5), category, safety_months\n",
    "\n",
    "            demand_std = series.std()\n",
    "            mean_demand = series.mean()\n",
    "\n",
    "            statistical_ss = z_score * demand_std * math.sqrt(lead_time)\n",
    "            velocity_min_ss = mean_demand * safety_months\n",
    "\n",
    "            final_ss = max(statistical_ss, velocity_min_ss)\n",
    "            min_ss = max(5, mean_demand * 0.25)\n",
    "            max_ss = mean_demand * lead_time * 2\n",
    "            final_ss = max(min_ss, min(final_ss, max_ss))\n",
    "\n",
    "            return max(round(final_ss), 5), category, safety_months\n",
    "\n",
    "        except Exception:\n",
    "            return 10, 'D', 1.0\n",
    "\n",
    "    def calculate_enhanced_reorder_point(self, series, lead_time, safety_stock):\n",
    "        try:\n",
    "            if series.empty or series.sum() == 0:\n",
    "                return safety_stock\n",
    "\n",
    "            avg_demand = series.mean() * lead_time\n",
    "            growth_rate = self._calculate_growth_rate(series)\n",
    "            trend_adjustment = growth_rate * lead_time\n",
    "\n",
    "            reorder_point = avg_demand + trend_adjustment + safety_stock\n",
    "            return max(round(reorder_point), safety_stock)\n",
    "\n",
    "        except:\n",
    "            return safety_stock\n",
    "\n",
    "    def calculate_enhanced_po_quantity(self, series, current_inventory, reorder_point, sku, safety_stock_months):\n",
    "        try:\n",
    "            if series.empty or series.sum() == 0:\n",
    "                if current_inventory < reorder_point:\n",
    "                    return max(20, reorder_point - current_inventory), \"NEW PRODUCT - Order Required\"\n",
    "                else:\n",
    "                    return 0, \"NEW PRODUCT - Sufficient Stock\"\n",
    "\n",
    "            monthly_demand = series.mean()\n",
    "            if monthly_demand <= 0:\n",
    "                return 0, \"No demand\"\n",
    "\n",
    "            sku_info = self.velocity_categories.get(sku, {})\n",
    "            velocity_category = sku_info.get('category', 'D')\n",
    "\n",
    "            if velocity_category == 'A':\n",
    "                order_months = 4.0\n",
    "            elif velocity_category == 'B':\n",
    "                order_months = 3.0\n",
    "            elif velocity_category == 'C':\n",
    "                order_months = 2.5\n",
    "            else:\n",
    "                order_months = 2.0\n",
    "\n",
    "            if current_inventory <= reorder_point:\n",
    "                shortage = reorder_point - current_inventory\n",
    "                target_stock = monthly_demand * (safety_stock_months + order_months)\n",
    "                po_quantity = max(shortage, target_stock - current_inventory)\n",
    "                urgency = \"HIGH - Below Reorder Point\"\n",
    "            elif current_inventory <= reorder_point * 1.3:\n",
    "                po_quantity = monthly_demand * order_months\n",
    "                urgency = \"MEDIUM - Approaching Reorder Point\"\n",
    "            else:\n",
    "                po_quantity = 0\n",
    "                urgency = \"LOW - Sufficient Stock\"\n",
    "\n",
    "            return round(po_quantity), urgency\n",
    "\n",
    "        except Exception:\n",
    "            return 0, \"Error\"\n",
    "\n",
    "    def calculate_future_orders(self, forecast, current_inventory, reorder_point, lead_time, safety_stock_months, sku):\n",
    "        try:\n",
    "            orders = []\n",
    "            running_inventory = current_inventory\n",
    "\n",
    "            sku_info = self.velocity_categories.get(sku, {})\n",
    "            velocity_category = sku_info.get('category', 'D')\n",
    "\n",
    "            if velocity_category == 'A':\n",
    "                order_months = 4.0\n",
    "            elif velocity_category == 'B':\n",
    "                order_months = 3.0\n",
    "            elif velocity_category == 'C':\n",
    "                order_months = 2.5\n",
    "            else:\n",
    "                order_months = 2.0\n",
    "\n",
    "            forecast_values = [f for f in forecast.iloc[:6] if f > 0]\n",
    "            if not forecast_values:\n",
    "                return [], [], []\n",
    "\n",
    "            avg_monthly_demand = sum(forecast_values) / len(forecast_values)\n",
    "            order_quantity = round(avg_monthly_demand * order_months)\n",
    "\n",
    "            for i in range(8):\n",
    "                month_demand = forecast.iloc[i] if i < len(forecast) else 0\n",
    "\n",
    "                if i + lead_time < 8:\n",
    "                    future_inventory = running_inventory\n",
    "\n",
    "                    for j in range(i, min(i + lead_time, 8)):\n",
    "                        future_demand = forecast.iloc[j] if j < len(forecast) else 0\n",
    "                        future_inventory -= future_demand\n",
    "\n",
    "                    if future_inventory <= reorder_point and order_quantity > 0:\n",
    "                        order_date = forecast.index[i] if i < len(forecast) else None\n",
    "                        arrival_date = forecast.index[min(i + lead_time, len(forecast)-1)] if i + lead_time < len(forecast) else None\n",
    "\n",
    "                        orders.append({\n",
    "                            'order_date': order_date,\n",
    "                            'arrival_date': arrival_date,\n",
    "                            'quantity': order_quantity\n",
    "                        })\n",
    "\n",
    "                        if i + lead_time < 8:\n",
    "                            running_inventory += order_quantity\n",
    "\n",
    "                running_inventory -= month_demand\n",
    "                running_inventory = max(0, running_inventory)\n",
    "\n",
    "            order_dates = []\n",
    "            order_qtys = []\n",
    "            arrival_dates = []\n",
    "\n",
    "            for order in orders[:3]:\n",
    "                order_dates.append(order['order_date'].strftime('%Y-%m-%d') if order['order_date'] else '')\n",
    "                order_qtys.append(order['quantity'])\n",
    "                arrival_dates.append(order['arrival_date'].strftime('%Y-%m-%d') if order['arrival_date'] else '')\n",
    "\n",
    "            while len(order_dates) < 3:\n",
    "                order_dates.append('')\n",
    "                order_qtys.append(0)\n",
    "                arrival_dates.append('')\n",
    "\n",
    "            return order_dates, order_qtys, arrival_dates\n",
    "\n",
    "        except Exception:\n",
    "            return ['', '', ''], [0, 0, 0], ['', '', '']\n",
    "\n",
    "    def calculate_months_of_inventory(self, current_inventory, forecast):\n",
    "        try:\n",
    "            if current_inventory <= 0:\n",
    "                return 0.0\n",
    "\n",
    "            forecast_values = [f for f in forecast.iloc[:6] if f > 0]\n",
    "\n",
    "            if not forecast_values or sum(forecast_values) == 0:\n",
    "                return 999.0\n",
    "\n",
    "            avg_monthly_demand = sum(forecast_values) / len(forecast_values)\n",
    "\n",
    "            if avg_monthly_demand <= 0:\n",
    "                return 999.0\n",
    "\n",
    "            months_available = current_inventory / avg_monthly_demand\n",
    "            return round(months_available, 1)\n",
    "\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    def create_enhanced_forecast(self, channel, inventory, product_info):\n",
    "        try:\n",
    "            print(f\"Creating enhanced forecast for {channel}...\")\n",
    "\n",
    "            all_skus = set()\n",
    "            all_skus.update(self.lead_times.keys())\n",
    "            all_skus.update(inventory.keys())\n",
    "            all_skus.update(product_info.keys())\n",
    "            all_skus.update(self.data['SKU'].unique())\n",
    "\n",
    "            print(f\"Processing {len(all_skus)} SKUs for {channel}\")\n",
    "\n",
    "            # Generate historical month labels (last 3 months)\n",
    "            current_date = pd.Timestamp.now()\n",
    "            historical_months = []\n",
    "            for i in range(3, 0, -1):  # 3, 2, 1 months ago\n",
    "                past_date = current_date - pd.DateOffset(months=i)\n",
    "                historical_months.append(past_date.strftime('%b_%Y'))\n",
    "\n",
    "            # Generate forecast month labels\n",
    "            forecast_months = []\n",
    "            for i in range(8):\n",
    "                future_date = current_date + pd.DateOffset(months=i+1)\n",
    "                forecast_months.append(future_date.strftime('%b_%Y'))  # e.g., 'Jun_2025'\n",
    "\n",
    "            print(f\"Historical periods: {', '.join(historical_months)}\")\n",
    "            print(f\"Forecast periods: {', '.join(forecast_months)}\")\n",
    "\n",
    "            forecast_data = []\n",
    "            products_found = 0\n",
    "\n",
    "            for i, sku in enumerate(all_skus):\n",
    "                try:\n",
    "                    if i % 20 == 0:\n",
    "                        print(f\"   Processing SKU {i+1}/{len(all_skus)}: {sku}\")\n",
    "\n",
    "                    series = self.prepare_data(channel, sku)\n",
    "                    forecast, method, seasonal_periods, seasonal_factors, growth_rate = self.generate_forecast(series)\n",
    "\n",
    "                    # Use enhanced SKU lookup for product names and launch dates\n",
    "                    product_name = self.smart_sku_lookup(sku, product_info)\n",
    "                    launch_date = self.smart_sku_lookup(sku, None, self.launch_dates)\n",
    "                    years_since_launch = self.calculate_years_since_launch(sku)\n",
    "\n",
    "                    # Debug: Show some matching attempts\n",
    "                    if i < 5 or (i % 50 == 0):\n",
    "                        print(f\"   DEBUG SKU {sku}: Product = '{product_name}'\")\n",
    "\n",
    "                    if product_name != 'Unknown':\n",
    "                        products_found += 1\n",
    "                    else:\n",
    "                        # Skip forecasts for SKUs without valid product mappings\n",
    "                        if i % 100 == 0:  # Only log occasionally to avoid spam\n",
    "                            print(f\"   Skipping SKU {sku} - no product mapping found\")\n",
    "                        continue\n",
    "\n",
    "                    # Get last 3 months sales\n",
    "                    last_3_sales = series.tail(3).tolist() if len(series) >= 3 else [0, 0, 0]\n",
    "                    while len(last_3_sales) < 3:\n",
    "                        last_3_sales.insert(0, 0)\n",
    "                    last_3_sales = last_3_sales[-3:]  # Ensure exactly 3 values\n",
    "\n",
    "                    # Ensure we have valid numeric values\n",
    "                    last_3_sales = [float(x) if not pd.isna(x) else 0.0 for x in last_3_sales]\n",
    "\n",
    "                    last_3_months_avg = round(series[-3:].mean(), 2) if len(series) >= 3 else round(series.mean(), 2) if not series.empty else 0\n",
    "                    # Handle NaN values\n",
    "                    if pd.isna(last_3_months_avg):\n",
    "                        last_3_months_avg = 0.0\n",
    "\n",
    "                    total_sales = round(series.sum(), 2)\n",
    "                    if pd.isna(total_sales):\n",
    "                        total_sales = 0.0\n",
    "                    lead_time = self.lead_times.get(sku, 2)\n",
    "\n",
    "                    safety_stock, velocity_category, safety_stock_months = self.calculate_enhanced_safety_stock(series, lead_time, sku)\n",
    "                    reorder_point = self.calculate_enhanced_reorder_point(series, lead_time, safety_stock)\n",
    "\n",
    "                    current_inventory = inventory.get(sku, 0)\n",
    "                    po_quantity, urgency = self.calculate_enhanced_po_quantity(series, current_inventory, reorder_point, sku, safety_stock_months)\n",
    "\n",
    "                    order_dates, order_qtys, arrival_dates = self.calculate_future_orders(forecast, current_inventory, reorder_point, lead_time, safety_stock_months, sku)\n",
    "                    months_of_inventory = self.calculate_months_of_inventory(current_inventory, forecast)\n",
    "\n",
    "                    sku_info = self.velocity_categories.get(sku, {})\n",
    "\n",
    "                    if current_inventory <= 0:\n",
    "                        stock_status = \"OUT OF STOCK\"\n",
    "                    elif current_inventory <= reorder_point:\n",
    "                        stock_status = \"REORDER NOW\"\n",
    "                    elif last_3_months_avg > 0 and current_inventory / last_3_months_avg < 1:\n",
    "                        stock_status = \"LOW STOCK\"\n",
    "                    elif last_3_months_avg > 0 and current_inventory / last_3_months_avg > 6:\n",
    "                        stock_status = \"OVERSTOCK\"\n",
    "                    else:\n",
    "                        stock_status = \"NORMAL\"\n",
    "\n",
    "                    # Create dynamic forecast columns with month/year labels\n",
    "                    row_data = {\n",
    "                        'SKU': str(sku),\n",
    "                        'Product_Name': product_name,\n",
    "                        'Launch_Date': launch_date.strftime('%Y-%m-%d') if launch_date and not pd.isna(launch_date) else '',\n",
    "                        'Years_Since_Launch': years_since_launch if years_since_launch is not None else '',\n",
    "                    }\n",
    "\n",
    "                    # Add historical months data with dynamic labels\n",
    "                    for idx, month_label in enumerate(historical_months):\n",
    "                        # Ensure we have a valid value for this index\n",
    "                        if idx < len(last_3_sales):\n",
    "                            value = int(last_3_sales[idx]) if not pd.isna(last_3_sales[idx]) else 0\n",
    "                        else:\n",
    "                            value = 0\n",
    "                        row_data[month_label] = value\n",
    "\n",
    "                    # Add current status columns\n",
    "                    row_data.update({\n",
    "                        'Current_Inventory': current_inventory,\n",
    "                        'Stock_Status': stock_status,\n",
    "                        'PO_Urgency': urgency,\n",
    "                        'Recommended_PO_Qty': po_quantity,\n",
    "                        'Next_Order_Date': order_dates[0],\n",
    "                        'Next_Order_Qty': order_qtys[0],\n",
    "                        'Next_Arrival_Date': arrival_dates[0],\n",
    "                        'Months_of_Inventory': months_of_inventory,\n",
    "                        'Velocity_Category': velocity_category,\n",
    "                        'Safety_Stock_Months': safety_stock_months,\n",
    "                        'Reorder_Point': reorder_point,\n",
    "                        'Safety_Stock': safety_stock,\n",
    "                    })\n",
    "\n",
    "                    # Add forecast columns with month/year labels\n",
    "                    for idx, month_label in enumerate(forecast_months):\n",
    "                        row_data[f'Forecast_{month_label}'] = int(forecast.iloc[idx]) if idx < len(forecast) else 0\n",
    "\n",
    "                    # Add remaining columns\n",
    "                    row_data.update({\n",
    "                        'Last_3_Months_Avg': last_3_months_avg,\n",
    "                        'Total_Sales': total_sales,\n",
    "                        'Growth_Rate': growth_rate if not pd.isna(growth_rate) else 0.0,\n",
    "                        'Order_2_Date': order_dates[1],\n",
    "                        'Order_2_Qty': order_qtys[1],\n",
    "                        'Order_2_Arrival': arrival_dates[1],\n",
    "                        'Order_3_Date': order_dates[2],\n",
    "                        'Order_3_Qty': order_qtys[2],\n",
    "                        'Order_3_Arrival': arrival_dates[2],\n",
    "                        'Lead_Time': lead_time,\n",
    "                        'Service_Level': f\"{sku_info.get('service_level', 0.85)*100:.0f}%\",\n",
    "                        'Monthly_Velocity': round(sku_info.get('monthly_velocity', 0), 1) if not pd.isna(sku_info.get('monthly_velocity', 0)) else 0.0,\n",
    "                        'Velocity_Rank': sku_info.get('rank', 999),\n",
    "                        'Channel': channel,\n",
    "                        'Forecast_Method': method,\n",
    "                    })\n",
    "\n",
    "                    forecast_data.append(row_data)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   Error processing SKU {sku}: {e}\")\n",
    "                    if i < 10:  # Show detailed errors for first 10 SKUs\n",
    "                        import traceback\n",
    "                        traceback.print_exc()\n",
    "                    continue\n",
    "\n",
    "            df = pd.DataFrame(forecast_data)\n",
    "\n",
    "            # Additional filtering to ensure we only have mapped products\n",
    "            if not df.empty:\n",
    "                initial_count = len(df)\n",
    "                df = df[df['Product_Name'] != 'Unknown']\n",
    "                final_count = len(df)\n",
    "                filtered_out = initial_count - final_count\n",
    "\n",
    "                if filtered_out > 0:\n",
    "                    print(f\"   Filtered out {filtered_out} SKUs without product mappings\")\n",
    "\n",
    "            print(f\"Generated {len(df)} forecasts for {channel} (only mapped products)\")\n",
    "            print(f\"‚úÖ Successfully mapped {products_found} product names\")\n",
    "\n",
    "            return df\n",
    "\n",
    "        except Exception:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def combine_channel_forecasts(self, amazon_forecast, shopify_forecast):\n",
    "        try:\n",
    "            print(\"Combining channel forecasts...\")\n",
    "\n",
    "            all_data = pd.concat([amazon_forecast, shopify_forecast], ignore_index=True)\n",
    "\n",
    "            if all_data.empty:\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            # Get forecast month columns dynamically\n",
    "            forecast_columns = [col for col in all_data.columns if col.startswith('Forecast_') and col != 'Forecast_Method']\n",
    "\n",
    "            # Get historical month columns dynamically\n",
    "            historical_columns = []\n",
    "            month_names = ['Jan_', 'Feb_', 'Mar_', 'Apr_', 'May_', 'Jun_', 'Jul_', 'Aug_', 'Sep_', 'Oct_', 'Nov_', 'Dec_']\n",
    "            for col in all_data.columns:\n",
    "                if any(month in col for month in month_names) and 'Forecast_' not in col and '_' in col:\n",
    "                    try:\n",
    "                        parts = col.split('_')\n",
    "                        if len(parts) == 2 and parts[0][:3] in [m[:3] for m in month_names]:\n",
    "                            historical_columns.append(col)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "            print(f\"Found historical columns: {historical_columns}\")\n",
    "            print(f\"Found forecast columns: {forecast_columns}\")\n",
    "\n",
    "            combined_data = []\n",
    "            unique_skus = all_data['SKU'].unique()\n",
    "\n",
    "            for sku in unique_skus:\n",
    "                sku_data = all_data[all_data['SKU'] == sku]\n",
    "\n",
    "                if sku_data.empty:\n",
    "                    continue\n",
    "\n",
    "                amazon_data = sku_data[sku_data['Channel'] == 'Amazon']\n",
    "                shopify_data = sku_data[sku_data['Channel'] == 'Shopify']\n",
    "\n",
    "                if not amazon_data.empty:\n",
    "                    base_record = amazon_data.iloc[0].copy()\n",
    "                else:\n",
    "                    base_record = shopify_data.iloc[0].copy()\n",
    "\n",
    "                combined_record = {\n",
    "                    'SKU': str(sku),\n",
    "                    'Product_Name': base_record.get('Product_Name', 'Unknown'),\n",
    "                    'Launch_Date': base_record.get('Launch_Date', ''),\n",
    "                    'Years_Since_Launch': base_record.get('Years_Since_Launch', ''),\n",
    "                }\n",
    "\n",
    "                # Add historical months data (sum across channels)\n",
    "                for col in historical_columns:\n",
    "                    combined_record[col] = int(sku_data[col].sum()) if col in sku_data.columns else 0\n",
    "\n",
    "                # Add current status columns\n",
    "                combined_record.update({\n",
    "                    'Current_Inventory': base_record.get('Current_Inventory', 0),\n",
    "                    'Stock_Status': base_record.get('Stock_Status', 'UNKNOWN'),\n",
    "                    'PO_Urgency': base_record.get('PO_Urgency', 'LOW'),\n",
    "                    'Recommended_PO_Qty': base_record.get('Recommended_PO_Qty', 0),\n",
    "                    'Next_Order_Date': base_record.get('Next_Order_Date', ''),\n",
    "                    'Next_Order_Qty': base_record.get('Next_Order_Qty', 0),\n",
    "                    'Next_Arrival_Date': base_record.get('Next_Arrival_Date', ''),\n",
    "                    'Months_of_Inventory': base_record.get('Months_of_Inventory', 0.0),\n",
    "                    'Velocity_Category': base_record.get('Velocity_Category', 'D'),\n",
    "                    'Safety_Stock_Months': base_record.get('Safety_Stock_Months', 1.0),\n",
    "                    'Reorder_Point': base_record.get('Reorder_Point', 0),\n",
    "                    'Safety_Stock': base_record.get('Safety_Stock', 0),\n",
    "                })\n",
    "\n",
    "                # Add combined forecast columns\n",
    "                for col in forecast_columns:\n",
    "                    combined_record[col] = int(sku_data[col].sum())\n",
    "\n",
    "                # Add channel breakdown for first 3 forecast months\n",
    "                if len(forecast_columns) >= 3:\n",
    "                    for i in range(3):\n",
    "                        month_col = forecast_columns[i]\n",
    "                        month_label = month_col.replace('Forecast_', '')\n",
    "                        combined_record[f'Amazon_{month_label}'] = int(amazon_data[month_col].iloc[0]) if not amazon_data.empty else 0\n",
    "                        combined_record[f'Shopify_{month_label}'] = int(shopify_data[month_col].iloc[0]) if not shopify_data.empty else 0\n",
    "\n",
    "                # Add remaining fields\n",
    "                combined_record.update({\n",
    "                    'Last_3_Months_Avg': round(sku_data['Last_3_Months_Avg'].sum(), 2) if not pd.isna(sku_data['Last_3_Months_Avg'].sum()) else 0.0,\n",
    "                    'Total_Sales': round(sku_data['Total_Sales'].sum(), 2) if not pd.isna(sku_data['Total_Sales'].sum()) else 0.0,\n",
    "                    'Growth_Rate': round(sku_data['Growth_Rate'].mean(), 2) if not pd.isna(sku_data['Growth_Rate'].mean()) else 0.0,\n",
    "                    'Order_2_Date': base_record.get('Order_2_Date', ''),\n",
    "                    'Order_2_Qty': base_record.get('Order_2_Qty', 0),\n",
    "                    'Order_2_Arrival': base_record.get('Order_2_Arrival', ''),\n",
    "                    'Order_3_Date': base_record.get('Order_3_Date', ''),\n",
    "                    'Order_3_Qty': base_record.get('Order_3_Qty', 0),\n",
    "                    'Order_3_Arrival': base_record.get('Order_3_Arrival', ''),\n",
    "                    'Lead_Time': base_record.get('Lead_Time', 2),\n",
    "                    'Service_Level': base_record.get('Service_Level', '85%'),\n",
    "                    'Monthly_Velocity': base_record.get('Monthly_Velocity', 0) if not pd.isna(base_record.get('Monthly_Velocity', 0)) else 0.0,\n",
    "                    'Velocity_Rank': base_record.get('Velocity_Rank', 999),\n",
    "                    'Channel': 'Combined',\n",
    "                    'Forecast_Method': 'Combined Channels',\n",
    "                })\n",
    "\n",
    "                combined_data.append(combined_record)\n",
    "\n",
    "            combined_df = pd.DataFrame(combined_data)\n",
    "            print(f\"Combined forecasts: {len(combined_df)} unique SKUs\")\n",
    "\n",
    "            return combined_df\n",
    "\n",
    "        except Exception:\n",
    "            return pd.concat([amazon_forecast, shopify_forecast], ignore_index=True)\n",
    "\n",
    "    def generate_actionable_insights(self, combined_forecast):\n",
    "        \"\"\"Generate comprehensive actionable insights for inventory planning.\"\"\"\n",
    "        try:\n",
    "            print(\"Generating actionable insights...\")\n",
    "\n",
    "            insights = {\n",
    "                'immediate_actions': [],\n",
    "                'weekly_actions': [],\n",
    "                'monthly_actions': [],\n",
    "                'risk_analysis': [],\n",
    "                'opportunities': [],\n",
    "                'cost_optimization': []\n",
    "            }\n",
    "\n",
    "            current_date = pd.Timestamp.now()\n",
    "\n",
    "            for _, row in combined_forecast.iterrows():\n",
    "                sku = row['SKU']\n",
    "                product_name = row['Product_Name']\n",
    "                current_inventory = row['Current_Inventory']\n",
    "                months_of_inventory = row['Months_of_Inventory']\n",
    "                # Handle NaN/Inf values\n",
    "                if pd.isna(months_of_inventory) or months_of_inventory == float('inf'):\n",
    "                    months_of_inventory = 999.0\n",
    "                elif months_of_inventory == float('-inf'):\n",
    "                    months_of_inventory = 0.0\n",
    "                po_urgency = row['PO_Urgency']\n",
    "                velocity_category = row['Velocity_Category']\n",
    "                reorder_point = row['Reorder_Point']\n",
    "                recommended_po = row['Recommended_PO_Qty']\n",
    "                lead_time = row['Lead_Time']\n",
    "\n",
    "                # Get forecast columns dynamically\n",
    "                forecast_cols = [col for col in row.index if col.startswith('Forecast_')]\n",
    "                next_3_months_demand = sum([row[col] for col in forecast_cols[:3] if not pd.isna(row[col])])\n",
    "\n",
    "                # IMMEDIATE ACTIONS (TODAY)\n",
    "                if current_inventory <= 0:\n",
    "                    lost_sales = next_3_months_demand * 50\n",
    "                    if pd.isna(lost_sales):\n",
    "                        lost_sales = 0\n",
    "                    insights['immediate_actions'].append({\n",
    "                        'Priority': 'CRITICAL',\n",
    "                        'SKU': sku,\n",
    "                        'Product': product_name,\n",
    "                        'Action': 'EXPEDITE ORDER IMMEDIATELY',\n",
    "                        'Reason': 'OUT OF STOCK',\n",
    "                        'Quantity': max(recommended_po, next_3_months_demand),\n",
    "                        'Impact': f'Lost sales: ~${lost_sales:.0f}/month',\n",
    "                        'Contact': 'Call supplier TODAY for expedited shipping'\n",
    "                    })\n",
    "\n",
    "                elif current_inventory <= reorder_point * 0.5:\n",
    "                    insights['immediate_actions'].append({\n",
    "                        'Priority': 'HIGH',\n",
    "                        'SKU': sku,\n",
    "                        'Product': product_name,\n",
    "                        'Action': 'Place PO Today',\n",
    "                        'Reason': f'Critically low: {months_of_inventory:.1f} months left',\n",
    "                        'Quantity': recommended_po,\n",
    "                        'Impact': f'Risk of stockout in {lead_time} months',\n",
    "                        'Contact': 'Email PO to supplier by EOD'\n",
    "                    })\n",
    "\n",
    "                # WEEKLY ACTIONS (This Week)\n",
    "                elif current_inventory <= reorder_point:\n",
    "                    insights['weekly_actions'].append({\n",
    "                        'Priority': 'MEDIUM',\n",
    "                        'SKU': sku,\n",
    "                        'Product': product_name,\n",
    "                        'Action': 'Place PO This Week',\n",
    "                        'Reason': 'At reorder point',\n",
    "                        'Quantity': recommended_po,\n",
    "                        'By_Date': (current_date + pd.Timedelta(days=7)).strftime('%Y-%m-%d'),\n",
    "                        'Notes': f'Lead time: {lead_time} months'\n",
    "                    })\n",
    "\n",
    "                # MONTHLY PLANNING\n",
    "                if row['Next_Order_Date']:\n",
    "                    next_order_date = pd.to_datetime(row['Next_Order_Date'])\n",
    "                    days_until_order = (next_order_date - current_date).days\n",
    "\n",
    "                    if 7 < days_until_order <= 30:\n",
    "                        budget_impact = row['Next_Order_Qty'] * 30\n",
    "                        if pd.isna(budget_impact):\n",
    "                            budget_impact = 0\n",
    "                        insights['monthly_actions'].append({\n",
    "                            'SKU': sku,\n",
    "                            'Product': product_name,\n",
    "                            'Action': 'Schedule PO',\n",
    "                            'Order_Date': row['Next_Order_Date'],\n",
    "                            'Quantity': row['Next_Order_Qty'],\n",
    "                            'Preparation': 'Confirm supplier capacity',\n",
    "                            'Budget_Impact': f'~${budget_impact:.0f}'\n",
    "                        })\n",
    "\n",
    "                # RISK ANALYSIS\n",
    "                if velocity_category == 'A' and months_of_inventory < 2:\n",
    "                    potential_loss = next_3_months_demand * 50\n",
    "                    if pd.isna(potential_loss):\n",
    "                        potential_loss = 0\n",
    "                    insights['risk_analysis'].append({\n",
    "                        'Risk_Level': 'HIGH',\n",
    "                        'SKU': sku,\n",
    "                        'Product': product_name,\n",
    "                        'Issue': 'Top seller with low inventory',\n",
    "                        'Potential_Loss': f'${potential_loss:.0f}',\n",
    "                        'Mitigation': 'Consider air freight or split shipments'\n",
    "                    })\n",
    "\n",
    "                elif months_of_inventory > 12:\n",
    "                    tied_capital = current_inventory * 30\n",
    "                    if pd.isna(tied_capital):\n",
    "                        tied_capital = 0\n",
    "                    insights['risk_analysis'].append({\n",
    "                        'Risk_Level': 'MEDIUM',\n",
    "                        'SKU': sku,\n",
    "                        'Product': product_name,\n",
    "                        'Issue': f'Excess inventory: {months_of_inventory:.0f} months',\n",
    "                        'Tied_Capital': f'${tied_capital:.0f}',\n",
    "                        'Mitigation': 'Pause orders, consider promotions'\n",
    "                    })\n",
    "\n",
    "                # OPPORTUNITIES\n",
    "                growth_rate = row.get('Growth_Rate', 0)\n",
    "                if pd.isna(growth_rate):\n",
    "                    growth_rate = 0\n",
    "                if growth_rate > 10 and months_of_inventory < 3:\n",
    "                    insights['opportunities'].append({\n",
    "                        'Type': 'GROWTH',\n",
    "                        'SKU': sku,\n",
    "                        'Product': product_name,\n",
    "                        'Trend': f'+{growth_rate:.0f}% growth',\n",
    "                        'Action': 'Increase safety stock',\n",
    "                        'Potential': 'Capture more market share'\n",
    "                    })\n",
    "\n",
    "                # COST OPTIMIZATION\n",
    "                if velocity_category in ['C', 'D'] and recommended_po > 0:\n",
    "                    insights['cost_optimization'].append({\n",
    "                        'SKU': sku,\n",
    "                        'Product': product_name,\n",
    "                        'Current_Order': recommended_po,\n",
    "                        'Suggestion': 'Combine with other orders',\n",
    "                        'Savings': 'Reduce shipping costs by 15-20%',\n",
    "                        'Action': 'Consolidate low-velocity orders monthly'\n",
    "                    })\n",
    "\n",
    "            return insights\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating insights: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def create_executive_summary(self, combined_forecast, insights):\n",
    "        \"\"\"Create executive summary with key metrics and actions.\"\"\"\n",
    "        try:\n",
    "            summary = {\n",
    "                'date': pd.Timestamp.now().strftime('%Y-%m-%d'),\n",
    "                'total_skus': len(combined_forecast),\n",
    "                'immediate_actions_required': len(insights.get('immediate_actions', [])),\n",
    "                'weekly_actions_required': len(insights.get('weekly_actions', [])),\n",
    "                'at_risk_skus': 0,\n",
    "                'overstock_skus': 0,\n",
    "                'total_inventory_value': 0,\n",
    "                'total_po_value_needed': 0,\n",
    "                'cash_flow_30_days': 0,\n",
    "                'cash_flow_60_days': 0,\n",
    "                'cash_flow_90_days': 0\n",
    "            }\n",
    "\n",
    "            # Calculate key metrics\n",
    "            for _, row in combined_forecast.iterrows():\n",
    "                current_inv = row['Current_Inventory']\n",
    "                months_inv = row['Months_of_Inventory']\n",
    "\n",
    "                # Inventory value (assuming $30 cost)\n",
    "                summary['total_inventory_value'] += current_inv * 30\n",
    "\n",
    "                # At risk SKUs\n",
    "                if months_inv < 2:\n",
    "                    summary['at_risk_skus'] += 1\n",
    "                elif months_inv > 6:\n",
    "                    summary['overstock_skus'] += 1\n",
    "\n",
    "                # PO values needed\n",
    "                if row['Recommended_PO_Qty'] > 0:\n",
    "                    summary['total_po_value_needed'] += row['Recommended_PO_Qty'] * 30\n",
    "\n",
    "                # Cash flow projections\n",
    "                if row['Next_Order_Date']:\n",
    "                    order_date = pd.to_datetime(row['Next_Order_Date'])\n",
    "                    days_until = (order_date - pd.Timestamp.now()).days\n",
    "                    order_value = row['Next_Order_Qty'] * 30\n",
    "\n",
    "                    if days_until <= 30:\n",
    "                        summary['cash_flow_30_days'] += order_value\n",
    "                    elif days_until <= 60:\n",
    "                        summary['cash_flow_60_days'] += order_value\n",
    "                    elif days_until <= 90:\n",
    "                        summary['cash_flow_90_days'] += order_value\n",
    "\n",
    "            return summary\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating executive summary: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def create_action_priority_matrix(self, combined_forecast):\n",
    "        \"\"\"Create action priority matrix based on velocity and urgency.\"\"\"\n",
    "        try:\n",
    "            priority_matrix = []\n",
    "\n",
    "            for _, row in combined_forecast.iterrows():\n",
    "                velocity = row['Velocity_Category']\n",
    "                months_inv = row['Months_of_Inventory']\n",
    "                po_urgency = row['PO_Urgency']\n",
    "\n",
    "                # Calculate priority score\n",
    "                velocity_score = {'A': 4, 'B': 3, 'C': 2, 'D': 1}.get(velocity, 1)\n",
    "\n",
    "                if months_inv <= 1:\n",
    "                    urgency_score = 4\n",
    "                elif months_inv <= 2:\n",
    "                    urgency_score = 3\n",
    "                elif months_inv <= 3:\n",
    "                    urgency_score = 2\n",
    "                else:\n",
    "                    urgency_score = 1\n",
    "\n",
    "                priority_score = velocity_score * urgency_score\n",
    "\n",
    "                if priority_score >= 12:\n",
    "                    action_priority = 'IMMEDIATE'\n",
    "                    action_timeline = 'Today'\n",
    "                elif priority_score >= 8:\n",
    "                    action_priority = 'HIGH'\n",
    "                    action_timeline = 'This Week'\n",
    "                elif priority_score >= 4:\n",
    "                    action_priority = 'MEDIUM'\n",
    "                    action_timeline = 'This Month'\n",
    "                else:\n",
    "                    action_priority = 'LOW'\n",
    "                    action_timeline = 'Next Month'\n",
    "\n",
    "                priority_matrix.append({\n",
    "                    'SKU': row['SKU'],\n",
    "                    'Product_Name': row['Product_Name'],\n",
    "                    'Velocity_Category': velocity,\n",
    "                    'Months_of_Inventory': months_inv if not pd.isna(months_inv) else 0.0,\n",
    "                    'Priority_Score': priority_score,\n",
    "                    'Action_Priority': action_priority,\n",
    "                    'Action_Timeline': action_timeline,\n",
    "                    'Recommended_Action': self._get_specific_action(row),\n",
    "                    'Order_Quantity': row['Recommended_PO_Qty'] if not pd.isna(row['Recommended_PO_Qty']) else 0,\n",
    "                    'Current_Inventory': row['Current_Inventory'] if not pd.isna(row['Current_Inventory']) else 0,\n",
    "                    'Next_Month_Forecast': row[[col for col in row.index if col.startswith('Forecast_')][0]] if any(col.startswith('Forecast_') for col in row.index) and not pd.isna(row[[col for col in row.index if col.startswith('Forecast_')][0]]) else 0\n",
    "                })\n",
    "\n",
    "            return pd.DataFrame(priority_matrix)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating priority matrix: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def _get_specific_action(self, row):\n",
    "        \"\"\"Get specific action recommendation based on SKU status.\"\"\"\n",
    "        current_inv = row.get('Current_Inventory', 0)\n",
    "        reorder_point = row.get('Reorder_Point', 0)\n",
    "        months_inv = row.get('Months_of_Inventory', 0)\n",
    "\n",
    "        # Handle NaN values\n",
    "        if pd.isna(current_inv):\n",
    "            current_inv = 0\n",
    "        if pd.isna(reorder_point):\n",
    "            reorder_point = 0\n",
    "        if pd.isna(months_inv):\n",
    "            months_inv = 0\n",
    "\n",
    "        if current_inv <= 0:\n",
    "            return 'EXPEDITE: Air freight required'\n",
    "        elif current_inv <= reorder_point * 0.5:\n",
    "            return 'URGENT: Place PO today, follow up with supplier'\n",
    "        elif current_inv <= reorder_point:\n",
    "            return 'REORDER: Standard PO this week'\n",
    "        elif months_inv > 12:\n",
    "            return 'PAUSE: No orders, plan clearance'\n",
    "        elif months_inv > 6:\n",
    "            return 'MONITOR: Reduce order quantities'\n",
    "        else:\n",
    "            return 'SCHEDULE: Follow standard ordering'\n",
    "\n",
    "    def create_finance_cash_flow_forecast(self, combined_forecast):\n",
    "        try:\n",
    "            print(\"Creating finance cash flow forecast...\")\n",
    "\n",
    "            if combined_forecast.empty:\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            finance_data = []\n",
    "            current_date = pd.Timestamp.now()\n",
    "\n",
    "            for _, row in combined_forecast.iterrows():\n",
    "                sku = row['SKU']\n",
    "                product_name = row['Product_Name']\n",
    "                velocity_category = row['Velocity_Category']\n",
    "\n",
    "                orders = []\n",
    "\n",
    "                if row['PO_Urgency'] == 'HIGH - Below Reorder Point' and row['Recommended_PO_Qty'] > 0:\n",
    "                    orders.append({\n",
    "                        'order_date': current_date.strftime('%Y-%m-%d'),\n",
    "                        'order_month': current_date.strftime('%Y-%m'),\n",
    "                        'quantity': row['Recommended_PO_Qty'],\n",
    "                        'urgency': 'IMMEDIATE'\n",
    "                    })\n",
    "\n",
    "                if row['Next_Order_Date'] and row['Next_Order_Qty'] > 0:\n",
    "                    try:\n",
    "                        order_date = pd.to_datetime(row['Next_Order_Date'])\n",
    "                        if order_date.year == current_date.year:\n",
    "                            orders.append({\n",
    "                                'order_date': order_date.strftime('%Y-%m-%d'),\n",
    "                                'order_month': order_date.strftime('%Y-%m'),\n",
    "                                'quantity': row['Next_Order_Qty'],\n",
    "                                'urgency': 'SCHEDULED'\n",
    "                            })\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                if row['Order_2_Date'] and row['Order_2_Qty'] > 0:\n",
    "                    try:\n",
    "                        order_date = pd.to_datetime(row['Order_2_Date'])\n",
    "                        if order_date.year == current_date.year:\n",
    "                            orders.append({\n",
    "                                'order_date': order_date.strftime('%Y-%m-%d'),\n",
    "                                'order_month': order_date.strftime('%Y-%m'),\n",
    "                                'quantity': row['Order_2_Qty'],\n",
    "                                'urgency': 'SCHEDULED'\n",
    "                            })\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                for order in orders:\n",
    "                    finance_record = {\n",
    "                        'Order_Month': order['order_month'],\n",
    "                        'Order_Date': order['order_date'],\n",
    "                        'SKU': sku,\n",
    "                        'Product_Name': product_name,\n",
    "                        'Velocity_Category': velocity_category,\n",
    "                        'Order_Quantity': order['quantity'],\n",
    "                        'Order_Urgency': order['urgency'],\n",
    "                        'Unit_Cost': '',\n",
    "                        'Total_Order_Value': '',\n",
    "                        'Supplier': '',\n",
    "                        'Payment_Terms': '',\n",
    "                        'Expected_Payment_Date': '',\n",
    "                        'Lead_Time': row['Lead_Time'],\n",
    "                        'Safety_Stock_Months': row['Safety_Stock_Months'],\n",
    "                        'Current_Inventory': row['Current_Inventory'],\n",
    "                        'Months_of_Inventory': row['Months_of_Inventory'],\n",
    "                    }\n",
    "\n",
    "                    finance_data.append(finance_record)\n",
    "\n",
    "            finance_df = pd.DataFrame(finance_data)\n",
    "\n",
    "            if not finance_df.empty:\n",
    "                finance_df['Order_Date_Sort'] = pd.to_datetime(finance_df['Order_Date'])\n",
    "                finance_df = finance_df.sort_values(['Order_Date_Sort', 'Velocity_Category', 'SKU'])\n",
    "                finance_df = finance_df.drop('Order_Date_Sort', axis=1)\n",
    "\n",
    "                print(f\"Created finance forecast: {len(finance_df)} orders planned\")\n",
    "\n",
    "            return finance_df\n",
    "\n",
    "        except Exception:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        import os\n",
    "        print(\"ENHANCED INVENTORY FORECASTING MODEL - COMPREHENSIVE VERSION\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        GOOGLE_SHEET_URL = \"https://docs.google.com/spreadsheets/d/1ZYugDxWgvmwye_zYYZJ4lgnY8hwZYKljEjGOKT2Cens/edit?gid=2126602512#gid=2126602512\"\n",
    "        WEEKLY_SALES_URL = \"https://docs.google.com/spreadsheets/d/16WVvbzcdzeeI4ZL4OFou_7DVM7UAHWUvXmpYiHzOUw0/edit?gid=46225766#gid=46225766\"\n",
    "        INVENTORY_URL = \"https://docs.google.com/spreadsheets/d/1_j7eJi52Kq8RHvK6e0RPBRK8wJ0DXUOMj7Z7yZHlZzM/edit?gid=404505721#gid=404505721\"\n",
    "        USE_GOOGLE_SHEETS = True\n",
    "\n",
    "        print(\"Loading data files...\")\n",
    "\n",
    "        historical_data = pd.read_csv('historical_sales.csv', sep=',', dtype={'SKU': str}, encoding='utf-8')\n",
    "        print(f\"   Historical sales: {len(historical_data)} records\")\n",
    "\n",
    "        # Clean historical SKUs more thoroughly\n",
    "        historical_data['SKU'] = historical_data['SKU'].astype(str).str.strip()\n",
    "        print(f\"   Sample historical SKUs: {historical_data['SKU'].unique()[:5]}\")\n",
    "\n",
    "        # MODIFIED SECTION - Load inventory from Google Sheets instead of CSV\n",
    "        inventory = {}\n",
    "        \n",
    "        if USE_GOOGLE_SHEETS and GOOGLE_SHEETS_AVAILABLE:\n",
    "            try:\n",
    "                print(f\"Current working directory: {os.getcwd()}\")\n",
    "                print(\"Looking for credentials file...\")\n",
    "\n",
    "                # Try multiple file paths\n",
    "                credential_paths = [\n",
    "                    'credentials.json',\n",
    "                    'service-account-key.json',\n",
    "                    r'C:\\Users\\samiw\\PycharmProjects\\Python_NewProject_First\\service-account-key.json',\n",
    "                    r'C:\\Users\\samiw\\PycharmProjects\\Python_NewProject_First\\credentials.json'\n",
    "                ]\n",
    "\n",
    "                credentials_file = None\n",
    "                for path in credential_paths:\n",
    "                    if os.path.exists(path):\n",
    "                        credentials_file = path\n",
    "                        print(f\"‚úÖ Found credentials file: {path}\")\n",
    "                        break\n",
    "\n",
    "                if not credentials_file:\n",
    "                    print(\"‚ùå No credentials file found. Falling back to CSV...\")\n",
    "                    raise FileNotFoundError(\"No credentials file found\")\n",
    "\n",
    "                gs_connector = GoogleSheetsConnector(credentials_file)\n",
    "\n",
    "                # Get inventory data from Google Sheets\n",
    "                print(f\"\\nüì¶ Loading inventory data from Google Sheets...\")\n",
    "                inventory = gs_connector.get_inventory_data(INVENTORY_URL)\n",
    "                print(f\"   Current inventory from Google Sheets: {len(inventory)} SKUs\")\n",
    "\n",
    "                # Get product info and lead times\n",
    "                product_info, lead_times, launch_dates = gs_connector.get_product_data(GOOGLE_SHEET_URL)\n",
    "\n",
    "                print(f\"   Product info from Google Sheets: {len(product_info)} SKUs\")\n",
    "                print(f\"   Lead times from Google Sheets: {len(lead_times)} SKUs\")\n",
    "                print(f\"   Launch dates from Google Sheets: {len([d for d in launch_dates.values() if d is not None])} SKUs\")\n",
    "\n",
    "                # Use the 'Amazon FBA' tab for weekly sales data\n",
    "                print(f\"\\nLoading Amazon FBA weekly sales data...\")\n",
    "                amazon_weekly_df = gs_connector.get_amazon_fba_weekly_sales(WEEKLY_SALES_URL)\n",
    "\n",
    "                if not amazon_weekly_df.empty:\n",
    "                    # Convert weekly to monthly and extend historical data\n",
    "                    amazon_weekly_monthly = gs_connector.convert_amazon_weekly_to_monthly(amazon_weekly_df)\n",
    "                    historical_data = gs_connector.extend_historical_data_with_amazon_weekly(historical_data, amazon_weekly_monthly)\n",
    "                    print(f\"‚úÖ Historical data extended with Amazon FBA weekly sales\")\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è  No Amazon FBA weekly sales data found - using historical data only\")\n",
    "\n",
    "                historical_skus = set(historical_data['SKU'].unique())\n",
    "                google_skus = set(product_info.keys())\n",
    "\n",
    "                print(f\"\\nüîç ENHANCED SKU MATCHING DEBUG:\")\n",
    "                print(f\"   Historical data has {len(historical_skus)} unique SKUs\")\n",
    "                print(f\"   Google Sheets has {len(google_skus)} unique SKUs\")\n",
    "\n",
    "                # Test direct matches\n",
    "                direct_matches = historical_skus.intersection(google_skus)\n",
    "                print(f\"   Direct matches: {len(direct_matches)}\")\n",
    "                print(f\"   Sample direct matches: {list(direct_matches)[:5]}\")\n",
    "\n",
    "                # Test the lookup function directly\n",
    "                print(f\"   Testing smart_sku_lookup function:\")\n",
    "                test_skus = ['810128951111', '810128951128', '810128951203']  # From the sample\n",
    "                for test_sku in test_skus:\n",
    "                    direct_result = product_info.get(test_sku, 'NOT_FOUND_DIRECT')\n",
    "                    print(f\"     {test_sku} -> Direct: {direct_result}\")\n",
    "\n",
    "                    # Test if it's in the set\n",
    "                    in_google_skus = test_sku in google_skus\n",
    "                    print(f\"     {test_sku} -> In google_skus: {in_google_skus}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error loading from Google Sheets: {e}\")\n",
    "                print(\"   Falling back to local CSV files...\")\n",
    "                USE_GOOGLE_SHEETS = False\n",
    "        else:\n",
    "            USE_GOOGLE_SHEETS = False\n",
    "\n",
    "        if not USE_GOOGLE_SHEETS:\n",
    "            # Fall back to CSV for inventory\n",
    "            inventory_df = pd.read_csv('current_inventory.csv', sep=',', dtype={'SKU': str}, encoding='utf-8')\n",
    "            inventory_df['SKU'] = inventory_df['SKU'].astype(str).str.strip()\n",
    "            inventory = dict(zip(inventory_df['SKU'], inventory_df['Inventory']))\n",
    "            print(f\"   Current inventory from CSV: {len(inventory)} SKUs\")\n",
    "            \n",
    "            lead_times_df = pd.read_csv('lead_times.csv', sep=',', dtype={'SKU': str}, encoding='utf-8')\n",
    "            lead_times_df['SKU'] = lead_times_df['SKU'].astype(str).str.strip()\n",
    "            lead_times = dict(zip(lead_times_df['SKU'], lead_times_df['LeadTime']))\n",
    "            print(f\"   Lead times from CSV: {len(lead_times)} SKUs\")\n",
    "\n",
    "            product_info_df = pd.read_csv('product_info.csv', sep=',', dtype={'Unit UPC': str}, encoding='utf-8')\n",
    "            if 'Unit UPC' in product_info_df.columns:\n",
    "                product_info_df = product_info_df.rename(columns={'Unit UPC': 'SKU'})\n",
    "            product_info_df['SKU'] = product_info_df['SKU'].astype(str).str.strip()\n",
    "            product_info = dict(zip(product_info_df['SKU'], product_info_df['Product Name']))\n",
    "            print(f\"   Product info from CSV: {len(product_info)} SKUs\")\n",
    "\n",
    "            # Create empty launch_dates for CSV fallback\n",
    "            launch_dates = {}\n",
    "            print(f\"   Launch dates: Not available in CSV mode\")\n",
    "\n",
    "        model = EnhancedForecastingModel(historical_data, lead_times, launch_dates, service_level=0.95)\n",
    "\n",
    "        print(\"\\nGenerating forecasts...\")\n",
    "        amazon_forecast = model.create_enhanced_forecast('Amazon', inventory, product_info)\n",
    "        shopify_forecast = model.create_enhanced_forecast('Shopify', inventory, product_info)\n",
    "\n",
    "        print(\"Creating combined channel analysis...\")\n",
    "        combined_forecast = model.combine_channel_forecasts(amazon_forecast, shopify_forecast)\n",
    "\n",
    "        # Generate actionable insights\n",
    "        print(\"Generating actionable insights...\")\n",
    "        insights = model.generate_actionable_insights(combined_forecast)\n",
    "        executive_summary = model.create_executive_summary(combined_forecast, insights)\n",
    "        priority_matrix = model.create_action_priority_matrix(combined_forecast)\n",
    "\n",
    "        finance_forecast = model.create_finance_cash_flow_forecast(combined_forecast)\n",
    "\n",
    "        timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M\")\n",
    "        data_source = \"GoogleSheets\" if USE_GOOGLE_SHEETS else \"CSV\"\n",
    "        filename = f'enhanced_forecast_COMPREHENSIVE_{data_source}_{timestamp}.xlsx'\n",
    "\n",
    "        print(f\"Saving results to {filename}...\")\n",
    "\n",
    "        with pd.ExcelWriter(filename, engine='xlsxwriter',\n",
    "                           engine_kwargs={'options': {'nan_inf_to_errors': True}}) as writer:\n",
    "            # Get the xlsxwriter workbook and worksheet objects\n",
    "            workbook = writer.book\n",
    "\n",
    "            # Define formats\n",
    "            header_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'text_wrap': True,\n",
    "                'valign': 'vcenter',\n",
    "                'align': 'center',\n",
    "                'bg_color': '#D7E4BC',\n",
    "                'border': 1,\n",
    "                'font_size': 10\n",
    "            })\n",
    "\n",
    "            urgent_format = workbook.add_format({\n",
    "                'bg_color': '#FFC7CE',\n",
    "                'font_color': '#9C0006',\n",
    "                'bold': True\n",
    "            })\n",
    "\n",
    "            warning_format = workbook.add_format({\n",
    "                'bg_color': '#FFEB9C',\n",
    "                'font_color': '#9C5700'\n",
    "            })\n",
    "\n",
    "            good_format = workbook.add_format({\n",
    "                'bg_color': '#C6EFCE',\n",
    "                'font_color': '#006100'\n",
    "            })\n",
    "\n",
    "            date_format = workbook.add_format({\n",
    "                'num_format': 'yyyy-mm-dd',\n",
    "                'align': 'center'\n",
    "            })\n",
    "\n",
    "            number_format = workbook.add_format({\n",
    "                'num_format': '#,##0',\n",
    "                'align': 'right'\n",
    "            })\n",
    "\n",
    "            decimal_format = workbook.add_format({\n",
    "                'num_format': '#,##0.0',\n",
    "                'align': 'right'\n",
    "            })\n",
    "\n",
    "            currency_format = workbook.add_format({\n",
    "                'num_format': '$#,##0',\n",
    "                'align': 'right'\n",
    "            })\n",
    "\n",
    "            text_format = workbook.add_format({\n",
    "                'text_wrap': True,\n",
    "                'valign': 'top'\n",
    "            })\n",
    "\n",
    "            # 1. EXECUTIVE SUMMARY SHEET (FIRST - MOST IMPORTANT)\n",
    "            exec_summary_data = pd.DataFrame([\n",
    "                ['INVENTORY PLANNING EXECUTIVE SUMMARY', ''],\n",
    "                ['Report Date:', executive_summary['date']],\n",
    "                ['', ''],\n",
    "                ['IMMEDIATE ACTIONS REQUIRED', ''],\n",
    "                ['Critical Actions (Today):', executive_summary['immediate_actions_required']],\n",
    "                ['High Priority (This Week):', executive_summary['weekly_actions_required']],\n",
    "                ['', ''],\n",
    "                ['INVENTORY HEALTH', ''],\n",
    "                ['Total SKUs:', executive_summary['total_skus']],\n",
    "                ['At-Risk SKUs (<2 months):', executive_summary['at_risk_skus']],\n",
    "                ['Overstock SKUs (>6 months):', executive_summary['overstock_skus']],\n",
    "                ['', ''],\n",
    "                ['FINANCIAL IMPACT', ''],\n",
    "                ['Current Inventory Value:', f\"${executive_summary['total_inventory_value']:,.0f}\"],\n",
    "                ['PO Value Needed (Immediate):', f\"${executive_summary['total_po_value_needed']:,.0f}\"],\n",
    "                ['', ''],\n",
    "                ['CASH FLOW PROJECTION', ''],\n",
    "                ['Next 30 Days:', f\"${executive_summary['cash_flow_30_days']:,.0f}\"],\n",
    "                ['Next 60 Days:', f\"${executive_summary['cash_flow_60_days']:,.0f}\"],\n",
    "                ['Next 90 Days:', f\"${executive_summary['cash_flow_90_days']:,.0f}\"],\n",
    "            ], columns=['Metric', 'Value'])\n",
    "\n",
    "            exec_summary_data.to_excel(writer, sheet_name='üìä Executive Summary', index=False, header=False)\n",
    "            worksheet = writer.sheets['üìä Executive Summary']\n",
    "\n",
    "            # Format executive summary with proper column widths\n",
    "            worksheet.set_column('A:A', 35)  # Metric column\n",
    "            worksheet.set_column('B:B', 25)  # Value column\n",
    "\n",
    "            # Format rows\n",
    "            title_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'font_size': 16,\n",
    "                'align': 'center',\n",
    "                'valign': 'vcenter',\n",
    "                'bg_color': '#4472C4',\n",
    "                'font_color': 'white',\n",
    "                'border': 1\n",
    "            })\n",
    "\n",
    "            section_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'font_size': 12,\n",
    "                'bg_color': '#D7E4BC',\n",
    "                'border': 1\n",
    "            })\n",
    "\n",
    "            value_format = workbook.add_format({\n",
    "                'font_size': 11,\n",
    "                'align': 'right'\n",
    "            })\n",
    "\n",
    "            # Apply formatting\n",
    "            worksheet.merge_range(0, 0, 0, 1, 'INVENTORY PLANNING EXECUTIVE SUMMARY', title_format)\n",
    "            worksheet.set_row(0, 30)\n",
    "\n",
    "            # Format section headers\n",
    "            for row in [3, 7, 12, 16]:\n",
    "                if row < len(exec_summary_data):\n",
    "                    worksheet.merge_range(row, 0, row, 1, exec_summary_data.iloc[row, 0], section_format)\n",
    "                    worksheet.set_row(row, 25)\n",
    "\n",
    "            # Format data rows\n",
    "            for row in range(1, len(exec_summary_data)):\n",
    "                if row not in [0, 3, 7, 12, 16] and exec_summary_data.iloc[row, 1]:\n",
    "                    worksheet.write(row, 1, exec_summary_data.iloc[row, 1], value_format)\n",
    "\n",
    "            # 2. IMMEDIATE ACTIONS SHEET\n",
    "            if insights['immediate_actions']:\n",
    "                immediate_df = pd.DataFrame(insights['immediate_actions'])\n",
    "                immediate_df.to_excel(writer, sheet_name='üö® IMMEDIATE ACTIONS', index=False, header=False, startrow=1)\n",
    "                worksheet = writer.sheets['üö® IMMEDIATE ACTIONS']\n",
    "\n",
    "                # Write headers\n",
    "                for col_num, column in enumerate(immediate_df.columns):\n",
    "                    worksheet.write(0, col_num, column, header_format)\n",
    "\n",
    "                # Set specific column widths for immediate actions\n",
    "                col_widths = {\n",
    "                    0: 12,  # Priority\n",
    "                    1: 15,  # SKU\n",
    "                    2: 35,  # Product\n",
    "                    3: 40,  # Action\n",
    "                    4: 30,  # Reason\n",
    "                    5: 10,  # Quantity\n",
    "                    6: 25,  # Impact\n",
    "                    7: 35   # Contact\n",
    "                }\n",
    "\n",
    "                for col, width in col_widths.items():\n",
    "                    if col < len(immediate_df.columns):\n",
    "                        worksheet.set_column(col, col, width)\n",
    "\n",
    "                # Apply row formatting for critical items\n",
    "                for row in range(1, len(immediate_df) + 1):\n",
    "                    if immediate_df.iloc[row-1]['Priority'] == 'CRITICAL':\n",
    "                        for col in range(len(immediate_df.columns)):\n",
    "                            worksheet.write(row, col, immediate_df.iloc[row-1, col], urgent_format)\n",
    "                    else:\n",
    "                        for col in range(len(immediate_df.columns)):\n",
    "                            worksheet.write(row, col, immediate_df.iloc[row-1, col], warning_format)\n",
    "\n",
    "                # Freeze header row\n",
    "                worksheet.freeze_panes(1, 0)\n",
    "\n",
    "            # 3. ACTION PRIORITY MATRIX\n",
    "            if not priority_matrix.empty:\n",
    "                priority_matrix.to_excel(writer, sheet_name='üìã Action Priority Matrix', index=False, header=False, startrow=1)\n",
    "                worksheet = writer.sheets['üìã Action Priority Matrix']\n",
    "\n",
    "                # Write headers\n",
    "                for col_num, column in enumerate(priority_matrix.columns):\n",
    "                    worksheet.write(0, col_num, column, header_format)\n",
    "\n",
    "                # Set column widths\n",
    "                matrix_widths = {\n",
    "                    'SKU': 15,\n",
    "                    'Product_Name': 35,\n",
    "                    'Velocity_Category': 10,\n",
    "                    'Months_of_Inventory': 12,\n",
    "                    'Priority_Score': 10,\n",
    "                    'Action_Priority': 12,\n",
    "                    'Action_Timeline': 15,\n",
    "                    'Recommended_Action': 40,\n",
    "                    'Order_Quantity': 12,\n",
    "                    'Current_Inventory': 12,\n",
    "                    'Next_Month_Forecast': 12\n",
    "                }\n",
    "\n",
    "                for i, col in enumerate(priority_matrix.columns):\n",
    "                    width = matrix_widths.get(col, 15)\n",
    "                    worksheet.set_column(i, i, width)\n",
    "\n",
    "                # Apply conditional formatting for priority levels\n",
    "                for row in range(1, len(priority_matrix) + 1):\n",
    "                    priority = priority_matrix.iloc[row-1]['Action_Priority']\n",
    "                    if priority == 'IMMEDIATE':\n",
    "                        row_format = urgent_format\n",
    "                    elif priority == 'HIGH':\n",
    "                        row_format = warning_format\n",
    "                    else:\n",
    "                        row_format = None\n",
    "\n",
    "                    if row_format:\n",
    "                        for col in range(len(priority_matrix.columns)):\n",
    "                            worksheet.write(row, col, priority_matrix.iloc[row-1, col], row_format)\n",
    "\n",
    "                worksheet.freeze_panes(1, 0)\n",
    "\n",
    "            # 4. WEEKLY ACTIONS\n",
    "            if insights['weekly_actions']:\n",
    "                weekly_df = pd.DataFrame(insights['weekly_actions'])\n",
    "                weekly_df.to_excel(writer, sheet_name='üìÖ Weekly Actions', index=False, header=False, startrow=1)\n",
    "                worksheet = writer.sheets['üìÖ Weekly Actions']\n",
    "\n",
    "                # Write headers and format\n",
    "                for col_num, column in enumerate(weekly_df.columns):\n",
    "                    worksheet.write(0, col_num, column, header_format)\n",
    "\n",
    "                # Set column widths\n",
    "                worksheet.set_column('A:A', 12)  # Priority\n",
    "                worksheet.set_column('B:B', 15)  # SKU\n",
    "                worksheet.set_column('C:C', 35)  # Product\n",
    "                worksheet.set_column('D:D', 25)  # Action\n",
    "                worksheet.set_column('E:E', 20)  # Reason\n",
    "                worksheet.set_column('F:F', 10)  # Quantity\n",
    "                worksheet.set_column('G:G', 12)  # By_Date\n",
    "                worksheet.set_column('H:H', 30)  # Notes\n",
    "\n",
    "                worksheet.freeze_panes(1, 0)\n",
    "\n",
    "            # 5. RISK ANALYSIS\n",
    "            if insights['risk_analysis']:\n",
    "                risk_df = pd.DataFrame(insights['risk_analysis'])\n",
    "                risk_df.to_excel(writer, sheet_name='‚ö†Ô∏è Risk Analysis', index=False, header=False, startrow=1)\n",
    "                worksheet = writer.sheets['‚ö†Ô∏è Risk Analysis']\n",
    "\n",
    "                # Write headers\n",
    "                for col_num, column in enumerate(risk_df.columns):\n",
    "                    worksheet.write(0, col_num, column, header_format)\n",
    "\n",
    "                # Set column widths\n",
    "                worksheet.set_column('A:A', 12)  # Risk_Level\n",
    "                worksheet.set_column('B:B', 15)  # SKU\n",
    "                worksheet.set_column('C:C', 35)  # Product\n",
    "                worksheet.set_column('D:D', 35)  # Issue\n",
    "                worksheet.set_column('E:E', 15)  # Potential_Loss\n",
    "                worksheet.set_column('F:F', 40)  # Mitigation\n",
    "\n",
    "                # Highlight high-risk items\n",
    "                for row in range(1, len(risk_df) + 1):\n",
    "                    if risk_df.iloc[row-1]['Risk_Level'] == 'HIGH':\n",
    "                        for col in range(len(risk_df.columns)):\n",
    "                            value = risk_df.iloc[row-1, col]\n",
    "                            # Handle NaN/Inf values\n",
    "                            if pd.isna(value):\n",
    "                                value = ''\n",
    "                            elif isinstance(value, (int, float)):\n",
    "                                if value == float('inf'):\n",
    "                                    value = 999999\n",
    "                                elif value == float('-inf'):\n",
    "                                    value = -999999\n",
    "                            worksheet.write(row, col, value, warning_format)\n",
    "\n",
    "                worksheet.freeze_panes(1, 0)\n",
    "\n",
    "            # 7. COST OPTIMIZATION SHEET\n",
    "            if insights.get('cost_optimization'):\n",
    "                cost_df = pd.DataFrame(insights['cost_optimization'])\n",
    "                cost_df.to_excel(writer, sheet_name='üí° Cost Optimization', index=False, header=False, startrow=1)\n",
    "                worksheet = writer.sheets['üí° Cost Optimization']\n",
    "\n",
    "                # Write headers\n",
    "                for col_num, column in enumerate(cost_df.columns):\n",
    "                    worksheet.write(0, col_num, column, header_format)\n",
    "\n",
    "                # Set column widths\n",
    "                worksheet.set_column('A:A', 15)  # SKU\n",
    "                worksheet.set_column('B:B', 35)  # Product\n",
    "                worksheet.set_column('C:C', 12)  # Current_Order\n",
    "                worksheet.set_column('D:D', 30)  # Suggestion\n",
    "                worksheet.set_column('E:E', 25)  # Savings\n",
    "                worksheet.set_column('F:F', 35)  # Action\n",
    "\n",
    "                worksheet.freeze_panes(1, 0)\n",
    "\n",
    "            # 6. OPPORTUNITIES SHEET\n",
    "            if insights['opportunities']:\n",
    "                opp_df = pd.DataFrame(insights['opportunities'])\n",
    "                opp_df.to_excel(writer, sheet_name='üéØ Opportunities', index=False, header=False, startrow=1)\n",
    "                worksheet = writer.sheets['üéØ Opportunities']\n",
    "\n",
    "                # Write headers\n",
    "                for col_num, column in enumerate(opp_df.columns):\n",
    "                    worksheet.write(0, col_num, column, header_format)\n",
    "\n",
    "                # Set column widths\n",
    "                worksheet.set_column('A:A', 12)  # Type\n",
    "                worksheet.set_column('B:B', 15)  # SKU\n",
    "                worksheet.set_column('C:C', 35)  # Product\n",
    "                worksheet.set_column('D:D', 20)  # Trend\n",
    "                worksheet.set_column('E:E', 25)  # Action\n",
    "                worksheet.set_column('F:F', 30)  # Potential\n",
    "\n",
    "                # Apply good formatting to all opportunity rows\n",
    "                for row in range(1, len(opp_df) + 1):\n",
    "                    for col in range(len(opp_df.columns)):\n",
    "                        worksheet.write(row, col, opp_df.iloc[row-1, col], good_format)\n",
    "\n",
    "                worksheet.freeze_panes(1, 0)\n",
    "\n",
    "            # 8. MONTHLY ACTIONS SHEET\n",
    "            if insights.get('monthly_actions'):\n",
    "                monthly_df = pd.DataFrame(insights['monthly_actions'])\n",
    "                monthly_df.to_excel(writer, sheet_name='üìÜ Monthly Actions', index=False, header=False, startrow=1)\n",
    "                worksheet = writer.sheets['üìÜ Monthly Actions']\n",
    "\n",
    "                # Write headers\n",
    "                for col_num, column in enumerate(monthly_df.columns):\n",
    "                    worksheet.write(0, col_num, column, header_format)\n",
    "\n",
    "                # Set column widths\n",
    "                worksheet.set_column('A:A', 15)  # SKU\n",
    "                worksheet.set_column('B:B', 35)  # Product\n",
    "                worksheet.set_column('C:C', 20)  # Action\n",
    "                worksheet.set_column('D:D', 12)  # Order_Date\n",
    "                worksheet.set_column('E:E', 10)  # Quantity\n",
    "                worksheet.set_column('F:F', 25)  # Preparation\n",
    "                worksheet.set_column('G:G', 15)  # Budget_Impact\n",
    "\n",
    "                worksheet.freeze_panes(1, 0)\n",
    "\n",
    "            # Function to format worksheet with proper column widths\n",
    "            def format_worksheet(worksheet, df, sheet_name):\n",
    "                # Write headers with formatting\n",
    "                for col_num, column in enumerate(df.columns):\n",
    "                    worksheet.write(0, col_num, column, header_format)\n",
    "\n",
    "                # Define optimal column widths based on column names and content\n",
    "                column_widths = {\n",
    "                    'SKU': 15,\n",
    "                    'Product_Name': 35,\n",
    "                    'Product': 35,\n",
    "                    'Launch_Date': 12,\n",
    "                    'Years_Since_Launch': 10,\n",
    "                    'Current_Inventory': 12,\n",
    "                    'Stock_Status': 15,\n",
    "                    'PO_Urgency': 25,\n",
    "                    'Recommended_PO_Qty': 15,\n",
    "                    'Next_Order_Date': 12,\n",
    "                    'Next_Order_Qty': 12,\n",
    "                    'Next_Arrival_Date': 12,\n",
    "                    'Months_of_Inventory': 12,\n",
    "                    'Velocity_Category': 10,\n",
    "                    'Safety_Stock_Months': 12,\n",
    "                    'Reorder_Point': 12,\n",
    "                    'Safety_Stock': 12,\n",
    "                    'Last_3_Months_Avg': 12,\n",
    "                    'Total_Sales': 12,\n",
    "                    'Growth_Rate': 10,\n",
    "                    'Order_2_Date': 12,\n",
    "                    'Order_2_Qty': 10,\n",
    "                    'Order_2_Arrival': 12,\n",
    "                    'Order_3_Date': 12,\n",
    "                    'Order_3_Qty': 10,\n",
    "                    'Order_3_Arrival': 12,\n",
    "                    'Lead_Time': 10,\n",
    "                    'Service_Level': 10,\n",
    "                    'Monthly_Velocity': 12,\n",
    "                    'Velocity_Rank': 10,\n",
    "                    'Channel': 10,\n",
    "                    'Forecast_Method': 20,\n",
    "                    'Priority': 12,\n",
    "                    'Action': 40,\n",
    "                    'Reason': 30,\n",
    "                    'Quantity': 10,\n",
    "                    'Impact': 30,\n",
    "                    'Contact': 35,\n",
    "                    'By_Date': 12,\n",
    "                    'Notes': 30,\n",
    "                    'Risk_Level': 12,\n",
    "                    'Issue': 35,\n",
    "                    'Potential_Loss': 15,\n",
    "                    'Mitigation': 40,\n",
    "                    'Order_Month': 12,\n",
    "                    'Order_Date': 12,\n",
    "                    'Order_Quantity': 12,\n",
    "                    'Order_Urgency': 15,\n",
    "                    'Unit_Cost': 10,\n",
    "                    'Total_Order_Value': 15,\n",
    "                    'Supplier': 20,\n",
    "                    'Payment_Terms': 15,\n",
    "                    'Expected_Payment_Date': 15,\n",
    "                    'Priority_Score': 10,\n",
    "                    'Action_Priority': 12,\n",
    "                    'Action_Timeline': 15,\n",
    "                    'Recommended_Action': 35,\n",
    "                    'Next_Month_Forecast': 12,\n",
    "                    'Type': 12,\n",
    "                    'Trend': 20,\n",
    "                    'Potential': 30,\n",
    "                    'Current_Order': 12,\n",
    "                    'Suggestion': 30,\n",
    "                    'Savings': 25,\n",
    "                    'Preparation': 30,\n",
    "                    'Budget_Impact': 15,\n",
    "                    'Metric': 30,\n",
    "                    'Value': 20,\n",
    "                    'Excess_Units': 12,\n",
    "                    'Excess_Value': 15,\n",
    "                    'SKU_Count': 10,\n",
    "                    'Inventory_Value': 15,\n",
    "                    'Order_Value': 12,\n",
    "                    'Arrival_Date': 12,\n",
    "                    'Mapping_Status': 20\n",
    "                }\n",
    "\n",
    "                # Set column widths\n",
    "                for i, col in enumerate(df.columns):\n",
    "                    # Check for specific column names first\n",
    "                    if col in column_widths:\n",
    "                        width = column_widths[col]\n",
    "                    # Check for forecast columns (dynamic month names)\n",
    "                    elif col.startswith('Forecast_'):\n",
    "                        width = 12\n",
    "                    # Check for month columns (Jan_2025, etc.)\n",
    "                    elif any(month in col for month in ['Jan_', 'Feb_', 'Mar_', 'Apr_', 'May_', 'Jun_', 'Jul_', 'Aug_', 'Sep_', 'Oct_', 'Nov_', 'Dec_']):\n",
    "                        width = 10\n",
    "                    # Check for Amazon/Shopify breakdown columns\n",
    "                    elif col.startswith('Amazon_') or col.startswith('Shopify_'):\n",
    "                        width = 12\n",
    "                    # Default widths based on data type\n",
    "                    else:\n",
    "                        # Calculate based on content\n",
    "                        max_len = len(str(col))\n",
    "                        for idx, value in enumerate(df[col][:10]):  # Check first 10 rows\n",
    "                            try:\n",
    "                                value_len = len(str(value)) if pd.notna(value) else 0\n",
    "                                max_len = max(max_len, value_len)\n",
    "                            except:\n",
    "                                pass\n",
    "                        width = min(max(max_len + 2, 8), 40)\n",
    "\n",
    "                    worksheet.set_column(i, i, width)\n",
    "\n",
    "                # Apply data formatting based on column type\n",
    "                for row_num in range(1, len(df) + 1):\n",
    "                    for col_num, col_name in enumerate(df.columns):\n",
    "                        value = df.iloc[row_num-1, col_num]\n",
    "\n",
    "                        # Handle NaN/Inf values\n",
    "                        if pd.isna(value):\n",
    "                            value = ''\n",
    "                        elif isinstance(value, (int, float)):\n",
    "                            if value == float('inf'):\n",
    "                                value = 999999\n",
    "                            elif value == float('-inf'):\n",
    "                                value = -999999\n",
    "                            elif pd.isna(value):\n",
    "                                value = 0\n",
    "\n",
    "                        # Apply formatting based on column type\n",
    "                        if 'Date' in col_name and value != '':\n",
    "                            try:\n",
    "                                # Convert to datetime for proper Excel date formatting\n",
    "                                if isinstance(value, str) and value:\n",
    "                                    date_value = pd.to_datetime(value)\n",
    "                                    worksheet.write_datetime(row_num, col_num, date_value, date_format)\n",
    "                                else:\n",
    "                                    worksheet.write(row_num, col_num, value, text_format)\n",
    "                            except:\n",
    "                                worksheet.write(row_num, col_num, value, text_format)\n",
    "\n",
    "                        elif col_name in ['Current_Inventory', 'Recommended_PO_Qty', 'Next_Order_Qty',\n",
    "                                         'Order_2_Qty', 'Order_3_Qty', 'Safety_Stock', 'Reorder_Point',\n",
    "                                         'Order_Quantity', 'Quantity', 'Excess_Units', 'SKU_Count'] or 'Forecast_' in col_name:\n",
    "                            try:\n",
    "                                if isinstance(value, (int, float)) and pd.notna(value):\n",
    "                                    worksheet.write(row_num, col_num, value, number_format)\n",
    "                                else:\n",
    "                                    worksheet.write(row_num, col_num, value, text_format)\n",
    "                            except:\n",
    "                                worksheet.write(row_num, col_num, value, text_format)\n",
    "\n",
    "                        elif col_name in ['Months_of_Inventory', 'Last_3_Months_Avg', 'Growth_Rate',\n",
    "                                         'Monthly_Velocity', 'Years_Since_Launch', 'Safety_Stock_Months']:\n",
    "                            try:\n",
    "                                if isinstance(value, (int, float)) and pd.notna(value):\n",
    "                                    worksheet.write(row_num, col_num, value, decimal_format)\n",
    "                                else:\n",
    "                                    worksheet.write(row_num, col_num, value, text_format)\n",
    "                            except:\n",
    "                                worksheet.write(row_num, col_num, value, text_format)\n",
    "\n",
    "                        elif col_name in ['Total_Order_Value', 'Inventory_Value', 'Excess_Value',\n",
    "                                         'Order_Value', 'Potential_Loss', 'Budget_Impact'] or 'Value' in col_name:\n",
    "                            try:\n",
    "                                if isinstance(value, (int, float)) and pd.notna(value):\n",
    "                                    worksheet.write(row_num, col_num, value, currency_format)\n",
    "                                else:\n",
    "                                    worksheet.write(row_num, col_num, value, text_format)\n",
    "                            except:\n",
    "                                worksheet.write(row_num, col_num, value, text_format)\n",
    "\n",
    "                        else:\n",
    "                            worksheet.write(row_num, col_num, value, text_format)\n",
    "\n",
    "                # Set row height for header\n",
    "                worksheet.set_row(0, 25)\n",
    "\n",
    "                # Freeze the header row and first two columns based on sheet type\n",
    "                if 'Executive' not in sheet_name:  # Don't freeze executive summary\n",
    "                    if 'All Forecasts' in sheet_name or 'Amazon' in sheet_name or 'Shopify' in sheet_name:\n",
    "                        worksheet.freeze_panes(1, 2)  # Freeze first 2 columns\n",
    "                    else:\n",
    "                        worksheet.freeze_panes(1, 0)  # Just freeze header row\n",
    "\n",
    "                # Add autofilter for data sheets\n",
    "                if len(df) > 0 and 'Executive' not in sheet_name:\n",
    "                    worksheet.autofilter(0, 0, len(df), len(df.columns) - 1)\n",
    "\n",
    "            # Write and format remaining sheets (after the special sheets)\n",
    "            if not combined_forecast.empty:\n",
    "                combined_forecast.to_excel(writer, sheet_name='üìà All Forecasts', index=False, header=False, startrow=1)\n",
    "                worksheet = writer.sheets['üìà All Forecasts']\n",
    "                format_worksheet(worksheet, combined_forecast, 'üìà All Forecasts')\n",
    "\n",
    "                # Add conditional formatting for Stock Status\n",
    "                status_col_idx = None\n",
    "                for i, col in enumerate(combined_forecast.columns):\n",
    "                    if col == 'Stock_Status':\n",
    "                        status_col_idx = i\n",
    "                        break\n",
    "\n",
    "                if status_col_idx is not None:\n",
    "                    for row in range(1, len(combined_forecast) + 1):\n",
    "                        status = combined_forecast.iloc[row-1]['Stock_Status']\n",
    "                        if status == 'OUT OF STOCK':\n",
    "                            worksheet.write(row, status_col_idx, status, urgent_format)\n",
    "                        elif status == 'REORDER NOW':\n",
    "                            worksheet.write(row, status_col_idx, status, warning_format)\n",
    "                        elif status == 'NORMAL':\n",
    "                            worksheet.write(row, status_col_idx, status, good_format)\n",
    "\n",
    "                # Apply conditional formatting for PO_Urgency\n",
    "                urgency_col_idx = None\n",
    "                for i, col in enumerate(combined_forecast.columns):\n",
    "                    if col == 'PO_Urgency':\n",
    "                        urgency_col_idx = i\n",
    "                        break\n",
    "\n",
    "                if urgency_col_idx is not None:\n",
    "                    for row in range(1, len(combined_forecast) + 1):\n",
    "                        urgency = combined_forecast.iloc[row-1]['PO_Urgency']\n",
    "                        if 'HIGH' in urgency:\n",
    "                            worksheet.write(row, urgency_col_idx, urgency, urgent_format)\n",
    "                        elif 'MEDIUM' in urgency:\n",
    "                            worksheet.write(row, urgency_col_idx, urgency, warning_format)\n",
    "\n",
    "            if not finance_forecast.empty:\n",
    "                finance_forecast.to_excel(writer, sheet_name='üí∞ Finance Cash Flow', index=False, header=False, startrow=1)\n",
    "                worksheet = writer.sheets['üí∞ Finance Cash Flow']\n",
    "                format_worksheet(worksheet, finance_forecast, 'üí∞ Finance Cash Flow')\n",
    "\n",
    "                # Apply specific formatting for finance sheet\n",
    "                finance_widths = {\n",
    "                    'Order_Month': 12,\n",
    "                    'Order_Date': 12,\n",
    "                    'SKU': 15,\n",
    "                    'Product_Name': 35,\n",
    "                    'Velocity_Category': 10,\n",
    "                    'Order_Quantity': 12,\n",
    "                    'Order_Urgency': 15,\n",
    "                    'Unit_Cost': 10,\n",
    "                    'Total_Order_Value': 15,\n",
    "                    'Supplier': 20,\n",
    "                    'Payment_Terms': 15,\n",
    "                    'Expected_Payment_Date': 18,\n",
    "                    'Lead_Time': 10,\n",
    "                    'Safety_Stock_Months': 12,\n",
    "                    'Current_Inventory': 12,\n",
    "                    'Months_of_Inventory': 12\n",
    "                }\n",
    "\n",
    "                for i, col in enumerate(finance_forecast.columns):\n",
    "                    if col in finance_widths:\n",
    "                        worksheet.set_column(i, i, finance_widths[col])\n",
    "\n",
    "                # Add a note for finance team\n",
    "                note_text = \"Please fill in Unit_Cost, Supplier, and Payment_Terms for accurate cash flow planning\"\n",
    "                worksheet.write(len(finance_forecast) + 3, 0, \"Note:\", header_format)\n",
    "                worksheet.merge_range(len(finance_forecast) + 3, 1, len(finance_forecast) + 3, 6, note_text, text_format)\n",
    "\n",
    "            if not amazon_forecast.empty:\n",
    "                amazon_forecast.to_excel(writer, sheet_name='üõí Amazon', index=False, header=False, startrow=1)\n",
    "                worksheet = writer.sheets['üõí Amazon']\n",
    "                format_worksheet(worksheet, amazon_forecast, 'üõí Amazon')\n",
    "\n",
    "            if not shopify_forecast.empty:\n",
    "                shopify_forecast.to_excel(writer, sheet_name='üõçÔ∏è Shopify', index=False, header=False, startrow=1)\n",
    "                worksheet = writer.sheets['üõçÔ∏è Shopify']\n",
    "                format_worksheet(worksheet, shopify_forecast, 'üõçÔ∏è Shopify')\n",
    "\n",
    "            # Additional analysis sheets with proper formatting\n",
    "\n",
    "            # Out of Stock Analysis\n",
    "            if 'Stock_Status' in combined_forecast.columns:\n",
    "                out_of_stock = combined_forecast[combined_forecast['Stock_Status'] == 'OUT OF STOCK']\n",
    "                if not out_of_stock.empty:\n",
    "                    out_of_stock.to_excel(writer, sheet_name='‚ùå Out of Stock', index=False, header=False, startrow=1)\n",
    "                    worksheet = writer.sheets['‚ùå Out of Stock']\n",
    "                    format_worksheet(worksheet, out_of_stock, '‚ùå Out of Stock')\n",
    "                    # Highlight all rows as critical\n",
    "                    for row in range(1, len(out_of_stock) + 1):\n",
    "                        worksheet.set_row(row, None, urgent_format)\n",
    "\n",
    "            # Reorder Now Analysis\n",
    "            if 'Stock_Status' in combined_forecast.columns:\n",
    "                reorder_now = combined_forecast[combined_forecast['Stock_Status'] == 'REORDER NOW']\n",
    "                if not reorder_now.empty:\n",
    "                    reorder_now.to_excel(writer, sheet_name='üì¶ Reorder Now', index=False, header=False, startrow=1)\n",
    "                    worksheet = writer.sheets['üì¶ Reorder Now']\n",
    "                    format_worksheet(worksheet, reorder_now, 'üì¶ Reorder Now')\n",
    "                    # Highlight all rows as warning\n",
    "                    for row in range(1, len(reorder_now) + 1):\n",
    "                        worksheet.set_row(row, None, warning_format)\n",
    "\n",
    "            # Overstock Analysis\n",
    "            if 'Months_of_Inventory' in combined_forecast.columns:\n",
    "                overstock = combined_forecast[combined_forecast['Months_of_Inventory'] > 6]\n",
    "                if not overstock.empty:\n",
    "                    overstock_analysis = overstock[['SKU', 'Product_Name', 'Current_Inventory', 'Months_of_Inventory',\n",
    "                                                   'Last_3_Months_Avg', 'Velocity_Category']].copy()\n",
    "                    overstock_analysis['Excess_Units'] = overstock_analysis['Current_Inventory'] - (overstock_analysis['Last_3_Months_Avg'] * 3)\n",
    "                    overstock_analysis['Excess_Value'] = overstock_analysis['Excess_Units'] * 30  # $30 cost assumption\n",
    "                    overstock_analysis.to_excel(writer, sheet_name='üìà Overstock Analysis', index=False, header=False, startrow=1)\n",
    "                    worksheet = writer.sheets['üìà Overstock Analysis']\n",
    "                    format_worksheet(worksheet, overstock_analysis, 'üìà Overstock Analysis')\n",
    "\n",
    "            # Velocity Analysis\n",
    "            if 'Velocity_Category' in combined_forecast.columns:\n",
    "                velocity_summary = combined_forecast.groupby('Velocity_Category').agg({\n",
    "                    'SKU': 'count',\n",
    "                    'Current_Inventory': 'sum',\n",
    "                    'Recommended_PO_Qty': 'sum'\n",
    "                }).rename(columns={'SKU': 'SKU_Count'})\n",
    "                velocity_summary['Inventory_Value'] = velocity_summary['Current_Inventory'] * 30\n",
    "                velocity_summary.to_excel(writer, sheet_name='‚ö° Velocity Analysis', startrow=1)\n",
    "                worksheet = writer.sheets['‚ö° Velocity Analysis']\n",
    "                # Format velocity analysis\n",
    "                worksheet.write(0, 0, 'Velocity_Category', header_format)\n",
    "                worksheet.write(0, 1, 'SKU_Count', header_format)\n",
    "                worksheet.write(0, 2, 'Current_Inventory', header_format)\n",
    "                worksheet.write(0, 3, 'Recommended_PO_Qty', header_format)\n",
    "                worksheet.write(0, 4, 'Inventory_Value', header_format)\n",
    "                worksheet.set_column('A:A', 15)\n",
    "                worksheet.set_column('B:B', 12)\n",
    "                worksheet.set_column('C:C', 15)\n",
    "                worksheet.set_column('D:D', 18)\n",
    "                worksheet.set_column('E:E', 15)\n",
    "\n",
    "            # Monthly Order Schedule\n",
    "            order_schedule = []\n",
    "            for _, row in combined_forecast.iterrows():\n",
    "                if row['Next_Order_Date']:\n",
    "                    order_schedule.append({\n",
    "                        'Order_Date': row['Next_Order_Date'],\n",
    "                        'SKU': row['SKU'],\n",
    "                        'Product': row['Product_Name'],\n",
    "                        'Quantity': row['Next_Order_Qty'],\n",
    "                        'Lead_Time': row['Lead_Time'],\n",
    "                        'Arrival_Date': row['Next_Arrival_Date']\n",
    "                    })\n",
    "                if row['Order_2_Date']:\n",
    "                    order_schedule.append({\n",
    "                        'Order_Date': row['Order_2_Date'],\n",
    "                        'SKU': row['SKU'],\n",
    "                        'Product': row['Product_Name'],\n",
    "                        'Quantity': row['Order_2_Qty'],\n",
    "                        'Lead_Time': row['Lead_Time'],\n",
    "                        'Arrival_Date': row['Order_2_Arrival']\n",
    "                    })\n",
    "\n",
    "            if order_schedule:\n",
    "                schedule_df = pd.DataFrame(order_schedule)\n",
    "                schedule_df['Order_Date'] = pd.to_datetime(schedule_df['Order_Date'])\n",
    "                schedule_df = schedule_df.sort_values('Order_Date')\n",
    "                schedule_df['Order_Value'] = schedule_df['Quantity'] * 30\n",
    "                # Convert back to string for Excel\n",
    "                schedule_df['Order_Date'] = schedule_df['Order_Date'].dt.strftime('%Y-%m-%d')\n",
    "                schedule_df.to_excel(writer, sheet_name='üìÖ Order Schedule', index=False, header=False, startrow=1)\n",
    "                worksheet = writer.sheets['üìÖ Order Schedule']\n",
    "                # Write headers\n",
    "                headers = ['Order_Date', 'SKU', 'Product', 'Quantity', 'Lead_Time', 'Arrival_Date', 'Order_Value']\n",
    "                for col_num, header in enumerate(headers):\n",
    "                    worksheet.write(0, col_num, header, header_format)\n",
    "                # Set column widths\n",
    "                worksheet.set_column('A:A', 12)  # Order_Date\n",
    "                worksheet.set_column('B:B', 15)  # SKU\n",
    "                worksheet.set_column('C:C', 35)  # Product\n",
    "                worksheet.set_column('D:D', 10)  # Quantity\n",
    "                worksheet.set_column('E:E', 10)  # Lead_Time\n",
    "                worksheet.set_column('F:F', 12)  # Arrival_Date\n",
    "                worksheet.set_column('G:G', 12)  # Order_Value\n",
    "                # Format data\n",
    "                for row_num in range(1, len(schedule_df) + 1):\n",
    "                    for col_num in range(len(headers)):\n",
    "                        value = schedule_df.iloc[row_num-1, col_num]\n",
    "                        if headers[col_num] == 'Order_Value':\n",
    "                            worksheet.write(row_num, col_num, value, currency_format)\n",
    "                        elif headers[col_num] in ['Quantity', 'Lead_Time']:\n",
    "                            worksheet.write(row_num, col_num, value, number_format)\n",
    "                        else:\n",
    "                            worksheet.write(row_num, col_num, value, text_format)\n",
    "                worksheet.freeze_panes(1, 0)\n",
    "                worksheet.autofilter(0, 0, len(schedule_df), len(headers) - 1)\n",
    "\n",
    "            # Create a mapping report to show which SKUs were matched vs filtered out\n",
    "            if not combined_forecast.empty:\n",
    "                # Show only mapped products in the main report\n",
    "                mapping_report = combined_forecast[['SKU', 'Product_Name', 'Launch_Date', 'Years_Since_Launch']].copy()\n",
    "                mapping_report['Mapping_Status'] = 'SUCCESSFULLY_MAPPED'\n",
    "                mapping_report.to_excel(writer, sheet_name='üîó Mapped Products', index=False, header=False, startrow=1)\n",
    "                worksheet = writer.sheets['üîó Mapped Products']\n",
    "                format_worksheet(worksheet, mapping_report, 'üîó Mapped Products')\n",
    "\n",
    "        print(f\"\\nüéâ SUCCESS! Comprehensive enhanced forecasting complete!\")\n",
    "        print(f\"Results saved to: {filename}\")\n",
    "        print(f\"Total mapped SKUs processed: {len(combined_forecast)}\")\n",
    "        print(f\"Data source: {'Google Sheets (with Inventory from ' + INVENTORY_URL + ')' if USE_GOOGLE_SHEETS else 'Local CSV files'}\")\n",
    "\n",
    "        # ACTIONABLE INSIGHTS SUMMARY\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä ACTIONABLE INSIGHTS SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        # Immediate Actions\n",
    "        if insights['immediate_actions']:\n",
    "            print(f\"\\nüö® IMMEDIATE ACTIONS REQUIRED ({len(insights['immediate_actions'])} items):\")\n",
    "            print(\"-\" * 50)\n",
    "            for action in insights['immediate_actions'][:5]:  # Show top 5\n",
    "                print(f\"‚Ä¢ {action['Product']} (SKU: {action['SKU']})\")\n",
    "                print(f\"  ACTION: {action['Action']}\")\n",
    "                print(f\"  REASON: {action['Reason']}\")\n",
    "                print(f\"  QUANTITY: {action['Quantity']} units\")\n",
    "                print(f\"  IMPACT: {action['Impact']}\")\n",
    "                print()\n",
    "\n",
    "        # Risk Analysis\n",
    "        high_risks = [r for r in insights['risk_analysis'] if r['Risk_Level'] == 'HIGH']\n",
    "        if high_risks:\n",
    "            print(f\"\\n‚ö†Ô∏è HIGH RISK ITEMS ({len(high_risks)} items):\")\n",
    "            print(\"-\" * 50)\n",
    "            for risk in high_risks[:3]:\n",
    "                print(f\"‚Ä¢ {risk['Product']} - {risk['Issue']}\")\n",
    "                print(f\"  POTENTIAL LOSS: {risk['Potential_Loss']}\")\n",
    "                print(f\"  MITIGATION: {risk['Mitigation']}\")\n",
    "                print()\n",
    "\n",
    "        # Cash Flow Summary\n",
    "        print(\"\\nüí∞ CASH FLOW REQUIREMENTS:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Next 30 days: ${executive_summary['cash_flow_30_days']:,.0f}\")\n",
    "        print(f\"Next 60 days: ${executive_summary['cash_flow_60_days']:,.0f}\")\n",
    "        print(f\"Next 90 days: ${executive_summary['cash_flow_90_days']:,.0f}\")\n",
    "        print(f\"Total PO Value Needed: ${executive_summary['total_po_value_needed']:,.0f}\")\n",
    "\n",
    "        # Inventory Health\n",
    "        print(\"\\nüì¶ INVENTORY HEALTH STATUS:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"At-Risk SKUs (<2 months inventory): {executive_summary['at_risk_skus']}\")\n",
    "        print(f\"Overstock SKUs (>6 months inventory): {executive_summary['overstock_skus']}\")\n",
    "        print(f\"Total Inventory Value: ${executive_summary['total_inventory_value']:,.0f}\")\n",
    "\n",
    "        # Top Actions by Priority\n",
    "        if not priority_matrix.empty:\n",
    "            immediate_actions = priority_matrix[priority_matrix['Action_Priority'] == 'IMMEDIATE']\n",
    "            high_actions = priority_matrix[priority_matrix['Action_Priority'] == 'HIGH']\n",
    "\n",
    "            print(f\"\\nüìã ACTION PRIORITY SUMMARY:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"IMMEDIATE actions required: {len(immediate_actions)} SKUs\")\n",
    "            print(f\"HIGH priority actions: {len(high_actions)} SKUs\")\n",
    "\n",
    "            if not immediate_actions.empty:\n",
    "                print(\"\\nTop 3 IMMEDIATE priorities:\")\n",
    "                for _, row in immediate_actions.head(3).iterrows():\n",
    "                    print(f\"‚Ä¢ {row['Product_Name']} - {row['Recommended_Action']}\")\n",
    "\n",
    "        # Quick Win Opportunities\n",
    "        if insights['opportunities']:\n",
    "            print(f\"\\nüéØ GROWTH OPPORTUNITIES ({len(insights['opportunities'])} items):\")\n",
    "            print(\"-\" * 50)\n",
    "            for opp in insights['opportunities'][:3]:\n",
    "                print(f\"‚Ä¢ {opp['Product']} - {opp['Trend']}\")\n",
    "                print(f\"  ACTION: {opp['Action']}\")\n",
    "                print()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚úÖ NEXT STEPS:\")\n",
    "        print(\"1. Review 'üö® IMMEDIATE ACTIONS' sheet and place urgent orders TODAY\")\n",
    "        print(\"2. Check 'üìä Executive Summary' for overall inventory health\")\n",
    "        print(\"3. Use 'üìã Action Priority Matrix' to plan this week's activities\")\n",
    "        print(\"4. Review '‚ö†Ô∏è Risk Analysis' to prevent stockouts\")\n",
    "        print(\"5. Share 'Finance Cash Flow' sheet with finance team for budget planning\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        # Enhanced summary of product mapping - only show mapped products\n",
    "        if not combined_forecast.empty and 'Product_Name' in combined_forecast.columns:\n",
    "            total_processed_skus = len(combined_forecast)\n",
    "\n",
    "            print(f\"\\nüìä PRODUCT MAPPING SUMMARY:\")\n",
    "            print(f\"   SKUs with valid product mappings: {total_processed_skus}\")\n",
    "            print(f\"   Mapping success rate: 100% (only mapped products included)\")\n",
    "            print(f\"   Inventory data source: Google Sheets\" if USE_GOOGLE_SHEETS else \"Local CSV\")\n",
    "\n",
    "            # Show some examples of successfully mapped products\n",
    "            if total_processed_skus > 0:\n",
    "                sample_mapped = combined_forecast[['SKU', 'Product_Name']].head(5)\n",
    "                print(f\"\\n‚úÖ Successfully mapped products (sample):\")\n",
    "                for _, row in sample_mapped.iterrows():\n",
    "                    print(f\"   {row['SKU']} -> {row['Product_Name']}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  No forecasts generated - check data sources and UPC mapping\")\n",
    "\n",
    "        print(\"\\n‚úÖ Ready for inventory planning decisions!\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {e}\")\n",
    "        print(\"   Make sure all CSV files are in the current directory:\")\n",
    "        print(\"   - historical_sales.csv\")\n",
    "        print(\"   - current_inventory.csv (if not using Google Sheets)\")\n",
    "        print(\"   - lead_times.csv\")\n",
    "        print(\"   - product_info.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037e7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
